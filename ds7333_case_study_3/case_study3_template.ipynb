{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoCXzNvN8g-8"
   },
   "source": [
    "# Case Study 3 - Email Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBy24RcB8g-9"
   },
   "source": [
    "__Team Members:__ Amber Clark, Andrew Leppla, Jorge Olmos, Paritosh Rai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emails are read in.  Kept: From, Subject, Body.\n",
    "- Remove \\n with regex\n",
    "- Remove other non-alphabetic characters - keep the counts?\n",
    "\n",
    "Feature Extraction:\n",
    "1. Vectorization - TFIDF (removes stop words)\n",
    "If we have time:\n",
    "2. Created 'trusted' and 'spam' email address book to filter spam - IS THIS OUT OF SCOPE PER SCOPE?\n",
    "\n",
    "Model:\n",
    "Classification with Naive Bayes - Amber, Jorge\n",
    "1. Subject Only = Baseline\n",
    "2. Body (+Subject?)\n",
    "\n",
    "Clustering:\n",
    "DBSCAN with cosine distance for NLP - Andrew, Paritosh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4O0up-U8g-9"
   },
   "source": [
    "# Content\n",
    "* [Business Understanding](#business-understanding)\n",
    "    - [Scope](#scope)\n",
    "    - [Introduction](#introduction)\n",
    "    - [Methods](#methods)\n",
    "    - [Results](#results)\n",
    "* [Data Evaluation](#data-evaluation)\n",
    "    - [Loading Data](#loading-data) \n",
    "    - [Data Summary](#data-summary)\n",
    "    - [Missing Values](#missing-values)\n",
    "    - [Feature Removal](#feature-removal)\n",
    "    - [Exploratory Data Analysis (EDA)](#eda)\n",
    "    - [Assumptions](#assumptions)\n",
    "* [Model Preparations](#model-preparations)\n",
    "    - [Sampling & Scaling Data](#sampling-scaling-data)\n",
    "    - [Proposed Method](#proposed-metrics)\n",
    "    - [Evaluation Metrics](#evaluation-metrics)\n",
    "    - [Feature Selection](#feature-selection)\n",
    "* [Model Building & Evaluations](#model-building)\n",
    "    - [Sampling Methodology](#sampling-methodology)\n",
    "    - [Model](#model)\n",
    "    - [Performance Analysis](#performance-analysis)\n",
    "* [Model Interpretability & Explainability](#model-explanation)\n",
    "    - [Examining Feature Importance](#examining-feature-importance)\n",
    "* [Conclusion](#conclusion)\n",
    "    - [Final Model Proposal](#final-model-proposal)\n",
    "    - [Future Considerations and Model Enhancements](#model-enhancements)\n",
    "    - [Alternative Modeling Approaches](#alternative-modeling-approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRedT-FB8g_A"
   },
   "source": [
    "# Business Understanding & Executive Summary <a id='business-understanding'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BiuuQOEh4"
   },
   "source": [
    "What are we trying to solve for and why is it important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TBIHKRt8g--"
   },
   "source": [
    "### Scope <a id='scope'/>\n",
    "\n",
    "\n",
    "### Introduction <a id='introduction'/>\n",
    "\n",
    "\n",
    "### Methods <a id='methods'/>\n",
    " \n",
    " \n",
    "### Results <a id='results'/>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVtcYu5j8g_B"
   },
   "source": [
    "# Data Evaluation <a id='data-evaluation'>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsIJIUSjOLcl"
   },
   "source": [
    "Summarize data being used?\n",
    "\n",
    "Are there missing values?\n",
    "\n",
    "Which variables are needed and which are not?\n",
    "\n",
    "What assumptions or conclusions are you drawing about your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox-qLqjc8g_B"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qcBcP8Jy8g_C",
    "outputId": "a6a85b4a-a106-48bb-bc2a-e6a5fb8ca494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import warnings\\nwarnings.filterwarnings('ignore')\\nfrom warnings import simplefilter \\nsimplefilter(action='ignore', category=FutureWarning)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "# email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tabulate import tabulate\n",
    "\n",
    "# data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from statistics import stdev\n",
    "\n",
    "# prediction models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import warnings filter\n",
    "'''import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WcvKI3y8g_C"
   },
   "source": [
    "## Loading Data <a id='loading-data'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDhb7boF8g_D"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript \n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'case_study3_template.ipynb'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3dYvb9W38g_D",
    "outputId": "3a6b397c-92dc-4ce0-c599-9cf69191e676"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_path = os.path.abspath(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\allep\\\\QTW_Projects\\\\QTW-SPRING-2022\\\\ds7333_case_study_3\\\\case_study3_template.ipynb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_spam = os.path.join(os.path.dirname(notebook_path), \"SpamAssassinMessages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\allep\\\\QTW_Projects\\\\QTW-SPRING-2022\\\\ds7333_case_study_3\\\\SpamAssassinMessages'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(folder):\n",
    "    file_list = []\n",
    "    if os.path.exists(folder):\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root,file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['easy_ham', 'easy_ham_2', 'hard_ham', 'spam', 'spam_2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = os.listdir(file_spam)\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file names in each folder (list of lists)\n",
    "files = [ os.listdir(file_spam+ '/'+ folder) for folder in folders] \n",
    "\n",
    "# Create a list of dataframes for all of the folders\n",
    "emails = [ pd.DataFrame({'folder' : [], 'from' : [], 'subject' : [], 'body': []}) ]*len(folders)\n",
    "\n",
    "# Add folder path to file names\n",
    "for i in range(0,len(folders)):\n",
    "    for j in range(0, len(files[i])):\n",
    "        files[i][j] = str(file_spam +'/' + folders[i] + '/' + files[i][j]) \n",
    "        \n",
    "        # Parse and extract email 'subject' and 'from'\n",
    "        with open(files[i][j], 'rb') as fp:\n",
    "            msg = BytesParser(policy=policy.default).parse(fp)\n",
    "            \n",
    "            # Error checking when reading in body for some html-based emails from spam folders\n",
    "            try:\n",
    "                simplest = msg.get_body(preferencelist=('plain', 'html'))\n",
    "                try:\n",
    "                    new_row = {'folder': folders[i], 'from': msg['from'], 'subject': msg['subject'], 'body': simplest.get_content()}\n",
    "                    emails[i] = emails[i].append(new_row, ignore_index=True)\n",
    "                except:\n",
    "                    new_row = {'folder': folders[i], 'from': msg['from'], 'subject':msg['subject'], 'body':'Error(html)'}\n",
    "                    emails[i] = emails[i].append(new_row, ignore_index=True)\n",
    "            except:\n",
    "                new_row = {'folder': folders[i], 'from': msg['from'], 'subject':msg['subject'], 'body':'Error(html)'}\n",
    "                emails[i] = emails[i].append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emails per folder\n",
    "print(\"# files in folders:\", [len(i) for i in files])\n",
    "print(\"# emails read in  :\", [i.shape[0] for i in emails])\n",
    "\n",
    "# Total emails\n",
    "print( \"\\n# total emails =\", sum([len(i) for i in files]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9353, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create single dataframe from all folders\n",
    "df = pd.concat( [emails[i] for i in range(0, len(emails))], axis=0)\n",
    "\n",
    "#  Keep the indices from the folders\n",
    "df = df.reset_index() \n",
    "\n",
    "# create response column from folder names\n",
    "spam = [(i=='spam' or i=='spam_2') for i in df['folder']]\n",
    "df = pd.concat([df, pd.Series(spam).astype(int)], axis=1)\n",
    "\n",
    "df.columns = ['folder_idx', 'folder', 'from', 'subject', 'body','spam']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAndSplit(raw_text): \n",
    "    temp = []\n",
    "    for word in raw_text.split():\n",
    "        temp.append(re.sub(r\"[^a-zA-Z0-9]\",\"\",word).lower())\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanBody(raw_content):\n",
    "    if(pd.isna(raw_content)):\n",
    "        return []\n",
    "    clean_from_html = cleanhtml(raw_content)\n",
    "    out = cleanAndSplit(clean_from_html)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(content):\n",
    "    #joined = [*content[], *content]\n",
    "    #print(content[['clean_body']])\n",
    "    #print(content[['clean_subject']])\n",
    "    #joined = content[['clean_body']], content[['clean_subject']]\n",
    "    joined = np.concatenate((*content[['clean_body']], *content[['clean_subject']]))\n",
    "    #print(joined)\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_body'] = df['body'].apply(cleanBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_subject'] = df['subject'].apply(cleanBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joined'] = df[['clean_body','clean_subject']].agg(combine, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_idx</th>\n",
       "      <th>folder</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Robert Elz &lt;kre@munnari.OZ.AU&gt;</td>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -05...</td>\n",
       "      <td>0</td>\n",
       "      <td>[date, wed, 21, aug, 2002, 105446, 0500, from,...</td>\n",
       "      <td>[re, new, sequences, window]</td>\n",
       "      <td>[date, wed, 21, aug, 2002, 105446, 0500, from,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Steve Burt &lt;Steve_Burt@cursor-system.com&gt;</td>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>[martin, a, posted, tassos, papadopoulos, the,...</td>\n",
       "      <td>[zzzzteana, re, alexander]</td>\n",
       "      <td>[martin, a, posted, tassos, papadopoulos, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Tim Chapman &lt;timc@2ubh.com&gt;</td>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>0</td>\n",
       "      <td>[man, threatens, explosion, in, moscow, thursd...</td>\n",
       "      <td>[zzzzteana, moscow, bomber]</td>\n",
       "      <td>[man, threatens, explosion, in, moscow, thursd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Monty Solomon &lt;monty@roscom.com&gt;</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>0</td>\n",
       "      <td>[klez, the, virus, that, wont, die, already, t...</td>\n",
       "      <td>[irr, klez, the, virus, that, wont, die]</td>\n",
       "      <td>[klez, the, virus, that, wont, die, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Stewart Smith &lt;Stewart.Smith@ee.ed.ac.uk&gt;</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[, in, adding, cream, to, spaghetti, carbonara...</td>\n",
       "      <td>[re, zzzzteana, nothing, like, mama, used, to,...</td>\n",
       "      <td>[, in, adding, cream, to, spaghetti, carbonara...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder_idx    folder                                       from  \\\n",
       "0           0  easy_ham             Robert Elz <kre@munnari.OZ.AU>   \n",
       "1           1  easy_ham  Steve Burt <Steve_Burt@cursor-system.com>   \n",
       "2           2  easy_ham                Tim Chapman <timc@2ubh.com>   \n",
       "3           3  easy_ham           Monty Solomon <monty@roscom.com>   \n",
       "4           4  easy_ham  Stewart Smith <Stewart.Smith@ee.ed.ac.uk>   \n",
       "\n",
       "                                          subject  \\\n",
       "0                        Re: New Sequences Window   \n",
       "1                       [zzzzteana] RE: Alexander   \n",
       "2                       [zzzzteana] Moscow bomber   \n",
       "3           [IRR] Klez: The Virus That  Won't Die   \n",
       "4  Re: [zzzzteana] Nothing like mama used to make   \n",
       "\n",
       "                                                body  spam  \\\n",
       "0      Date:        Wed, 21 Aug 2002 10:54:46 -05...     0   \n",
       "1  Martin A posted:\\nTassos Papadopoulos, the Gre...     0   \n",
       "2  Man Threatens Explosion In Moscow \\n\\nThursday...     0   \n",
       "3  Klez: The Virus That Won't Die\\n \\nAlready the...     0   \n",
       "4  >  in adding cream to spaghetti carbonara, whi...     0   \n",
       "\n",
       "                                          clean_body  \\\n",
       "0  [date, wed, 21, aug, 2002, 105446, 0500, from,...   \n",
       "1  [martin, a, posted, tassos, papadopoulos, the,...   \n",
       "2  [man, threatens, explosion, in, moscow, thursd...   \n",
       "3  [klez, the, virus, that, wont, die, already, t...   \n",
       "4  [, in, adding, cream, to, spaghetti, carbonara...   \n",
       "\n",
       "                                       clean_subject  \\\n",
       "0                       [re, new, sequences, window]   \n",
       "1                         [zzzzteana, re, alexander]   \n",
       "2                        [zzzzteana, moscow, bomber]   \n",
       "3           [irr, klez, the, virus, that, wont, die]   \n",
       "4  [re, zzzzteana, nothing, like, mama, used, to,...   \n",
       "\n",
       "                                              joined  \n",
       "0  [date, wed, 21, aug, 2002, 105446, 0500, from,...  \n",
       "1  [martin, a, posted, tassos, papadopoulos, the,...  \n",
       "2  [man, threatens, explosion, in, moscow, thursd...  \n",
       "3  [klez, the, virus, that, wont, die, already, t...  \n",
       "4  [, in, adding, cream, to, spaghetti, carbonara...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul_6nw48N5Dy"
   },
   "source": [
    "## Data Summary <a id='data-summary'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aws5HAx98g_E"
   },
   "source": [
    "## Missing Values <a id='missing-values'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BgB13po8g_F",
    "outputId": "aba28207-2ccb-4d38-b36a-adcd6d28dd45"
   },
   "outputs": [],
   "source": [
    "# Rows where body couldn't be read in = 'Error(html)'\n",
    "df.loc[df['body']=='Error(html)']\n",
    "\n",
    "# All spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of body read Errors\n",
    "df.loc[df['body']=='Error(html)'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at file example with Error(html)\n",
    "with open(files[4][1], 'rb') as fp:\n",
    "    msg = BytesParser(policy=policy.default).parse(fp)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN and None values with 'No Subject'\n",
    "df.loc[ df['subject'].isna(), 'subject'] = 'No Subject'\n",
    "df.loc[ df['subject']=='', 'subject'] = 'No Subject'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21Kdalsl8g_I"
   },
   "source": [
    "## Feature Removal <a id='feature-removal'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "786e5_En8g_J"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbvlZHwG8g_J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbAmkozvN5Dz"
   },
   "source": [
    "## Exploratory Data Analysis (EDA) <a id='eda'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6954\n",
       "1    2399\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChoPhHdx8g_M"
   },
   "source": [
    "### Clustering\n",
    "- Use DBSCAN with cosine distance for NLP.  \n",
    "- Try to keep the clusters balanced and get approx. 5 clusters to dissect and explain\n",
    "- Look for descriptors for the clusters, like business vs. personal emails, IT emails, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "vectorizer = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf = TfidfVectorizer(stop_words='english', strip_accents='unicode', lowercase=True)\n",
    "\n",
    "features_subject = vectorizer.fit_transform(df['clean_subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andrew to replace stdev with node purity calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EqDlP8C_N5D0",
    "outputId": "8ec90270-f4e0-4210-c59a-64c9b6deb27c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>cluster counts</th>\n",
       "      <th># clusters</th>\n",
       "      <th>count stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>0.80</td>\n",
       "      <td>[4497, 131]</td>\n",
       "      <td>2</td>\n",
       "      <td>3087.228207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>0.70</td>\n",
       "      <td>[133, 761, 124]</td>\n",
       "      <td>3</td>\n",
       "      <td>365.201771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[1752, 133, 111, 123]</td>\n",
       "      <td>4</td>\n",
       "      <td>814.882967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[3783, 133, 52, 54]</td>\n",
       "      <td>4</td>\n",
       "      <td>1852.050845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>[6529, 131, 31, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>3237.638272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.65</td>\n",
       "      <td>[133, 147, 140, 103, 155]</td>\n",
       "      <td>5</td>\n",
       "      <td>19.969977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>[70, 133, 73, 1775, 51, 50, 37, 50]</td>\n",
       "      <td>8</td>\n",
       "      <td>604.846247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>[70, 133, 70, 147, 51, 50, 163, 275, 35, 59, 2...</td>\n",
       "      <td>12</td>\n",
       "      <td>82.362098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_samples  epsilon                                     cluster counts  \\\n",
       "7          100     0.80                                        [4497, 131]   \n",
       "5          100     0.70                                    [133, 761, 124]   \n",
       "6          100     0.75                              [1752, 133, 111, 123]   \n",
       "2           50     0.75                                [3783, 133, 52, 54]   \n",
       "3           50     0.80                                 [6529, 131, 31, 2]   \n",
       "4          100     0.65                          [133, 147, 140, 103, 155]   \n",
       "1           50     0.70                [70, 133, 73, 1775, 51, 50, 37, 50]   \n",
       "0           50     0.65  [70, 133, 70, 147, 51, 50, 163, 275, 35, 59, 2...   \n",
       "\n",
       "   # clusters  count stdev  \n",
       "7           2  3087.228207  \n",
       "5           3   365.201771  \n",
       "6           4   814.882967  \n",
       "2           4  1852.050845  \n",
       "3           4  3237.638272  \n",
       "4           5    19.969977  \n",
       "1           8   604.846247  \n",
       "0          12    82.362098  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(metric='cosine', min_samples=125)\n",
    "eps_clusters = []\n",
    "\n",
    "for j in range(50,101,50):\n",
    "    dbscan.min_samples = j\n",
    "    for i in range(65,81,5):\n",
    "        dbscan.eps = i/100\n",
    "        clustering = dbscan.fit_predict(features_subject)\n",
    "        cluster_counts = list( pd.Series( clustering ).value_counts().sort_index() )\n",
    "        cluster_counts.pop(0) # remove -1 cluster which is a non-cluster \n",
    "        num_clusters = len(cluster_counts)\n",
    "        eps_clusters.append([ dbscan.min_samples, dbscan.eps, cluster_counts, num_clusters, stdev(cluster_counts) ])\n",
    "\n",
    "clusters_df = pd.DataFrame(eps_clusters, columns = ['min_samples','epsilon', 'cluster counts', '# clusters','count stdev'])\n",
    "clusters_df.sort_values(by=['# clusters', 'count stdev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Clusters - Insights\n",
    "\n",
    "5 clusters with stdev=90 (min_samples=100, epsilon=0.65) was by far the most balanced set of clusters with 100-150 emails in each cluster.\n",
    "\n",
    "- Cluster 0 : News & Dates\n",
    "- Cluster 1 : Pain (Ouch, hurts)\n",
    "- Cluster 2 : [Spambayes] \n",
    "- Cluster 3 : IT\n",
    "- Cluster 4 : [Spambayes] & package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head & tail of each cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>[use, perl, headlines, for, 20020830]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>[ntk, now, 20020830]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>[use, perl, headlines, for, 20021008]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0</td>\n",
       "      <td>[use, perl, stories, for, 20020820]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6661</th>\n",
       "      <td>0</td>\n",
       "      <td>[use, perl, stories, for, 20020818]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>0</td>\n",
       "      <td>[use, perl, stories, for, 20020818]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>[re, ouch, ouch, ouch, ouch, ouchwas, re, my, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>[re, ouch, ouch, ouch, ouch, ouchwas, re, my, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1</td>\n",
       "      <td>[ouch]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>1</td>\n",
       "      <td>[re, my, brain, hurts]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>1</td>\n",
       "      <td>[re, my, brain, hurts]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>1</td>\n",
       "      <td>[re, my, brain, hurts]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>2</td>\n",
       "      <td>[spambayes, test, sets]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2</td>\n",
       "      <td>[spambayes, test, sets]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2</td>\n",
       "      <td>[spambayes, test, sets]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>2</td>\n",
       "      <td>[spambayes, spambayes, package]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>2</td>\n",
       "      <td>[spambayes, spambayes, package]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>2</td>\n",
       "      <td>[spambayes, spambayes, package]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>3</td>\n",
       "      <td>[razorusers, razor, with, sendmail]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>3</td>\n",
       "      <td>[razorusers, razor, 214, , the, day, after]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>3</td>\n",
       "      <td>[re, razorusers, razor, 214, , the, day, after]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>3</td>\n",
       "      <td>[re, razorusers, re, whats, wrong, with, the, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>3</td>\n",
       "      <td>[razorusers, upgraded, to, razor, 214]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>3</td>\n",
       "      <td>[re, razorusers, upgraded, to, razor, 214]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>[re, erratum, re, no, matter, , , errors]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>4</td>\n",
       "      <td>[re, erratum, re, no, matter, , , errors]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>4</td>\n",
       "      <td>[re, erratum, re, no, matter, , , errors]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>4</td>\n",
       "      <td>[, usa, business, search, cd, ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>4</td>\n",
       "      <td>[, youre, approved, ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>4</td>\n",
       "      <td>[yyyy, your, computer, can, read, , ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster                                      clean_subject  spam\n",
       "65          0              [use, perl, headlines, for, 20020830]     0\n",
       "69          0                               [ntk, now, 20020830]     0\n",
       "140         0              [use, perl, headlines, for, 20021008]     0\n",
       "6432        0                [use, perl, stories, for, 20020820]     0\n",
       "6661        0                [use, perl, stories, for, 20020818]     0\n",
       "6878        0                [use, perl, stories, for, 20020818]     0\n",
       "329         1  [re, ouch, ouch, ouch, ouch, ouchwas, re, my, ...     0\n",
       "340         1  [re, ouch, ouch, ouch, ouch, ouchwas, re, my, ...     0\n",
       "467         1                                             [ouch]     0\n",
       "5900        1                             [re, my, brain, hurts]     0\n",
       "5908        1                             [re, my, brain, hurts]     0\n",
       "5915        1                             [re, my, brain, hurts]     0\n",
       "1559        2                            [spambayes, test, sets]     0\n",
       "1561        2                            [spambayes, test, sets]     0\n",
       "1563        2                            [spambayes, test, sets]     0\n",
       "4336        2                    [spambayes, spambayes, package]     0\n",
       "4337        2                    [spambayes, spambayes, package]     0\n",
       "4341        2                    [spambayes, spambayes, package]     0\n",
       "1539        3                [razorusers, razor, with, sendmail]     0\n",
       "1540        3        [razorusers, razor, 214, , the, day, after]     0\n",
       "1541        3    [re, razorusers, razor, 214, , the, day, after]     0\n",
       "5705        3  [re, razorusers, re, whats, wrong, with, the, ...     0\n",
       "5709        3             [razorusers, upgraded, to, razor, 214]     0\n",
       "5711        3         [re, razorusers, upgraded, to, razor, 214]     0\n",
       "997         4          [re, erratum, re, no, matter, , , errors]     0\n",
       "1003        4          [re, erratum, re, no, matter, , , errors]     0\n",
       "1031        4          [re, erratum, re, no, matter, , , errors]     0\n",
       "9293        4                    [, usa, business, search, cd, ]     1\n",
       "9302        4                              [, youre, approved, ]     1\n",
       "9334        4              [yyyy, your, computer, can, read, , ]     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most clusters with the lowest spread (stdev) in cluster counts\n",
    "dbscan.min_samples = 100\n",
    "dbscan.eps = 0.65\n",
    "\n",
    "clusters = dbscan.fit_predict(features_subject)\n",
    "clusters = pd.Series(clusters)\n",
    "clusters.index = df.index\n",
    "subject_clusters = pd.concat([ clusters, df['clean_subject'], df['spam'] ], axis=1)\n",
    "subject_clusters.columns = ['cluster','clean_subject', 'spam']\n",
    "\n",
    "heads_tails = pd.DataFrame({'cluster' : [], 'clean_subject' : [], 'spam' : []}) \n",
    "for i in range( 0, max(clusters.unique())+1 ): # Exclude the -1 class which is a non-cluster\n",
    "    heads_tails = pd.concat([heads_tails, \n",
    "                             subject_clusters.loc[subject_clusters['cluster']==i].head(3),\n",
    "                             subject_clusters.loc[subject_clusters['cluster']==i].tail(3) ], axis=0)\n",
    "heads_tails[['cluster', 'spam']] = heads_tails[['cluster','spam']].astype(int)\n",
    "print('Head & tail of each cluster:')    \n",
    "heads_tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 83 spam cases, all in Cluster 4.  Clusters 0-3 have no spam and can be used for filtering or pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    595\n",
       "1     83\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_clusters.loc[subject_clusters['cluster']!=-1,'spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    83\n",
       "0    72\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_clusters.loc[subject_clusters['cluster']==4,'spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgZRFeORN5D3"
   },
   "source": [
    "### Feature Collinearity <a id='feature-collinearity'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8bqfy9fN5D3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXZZeARjN5D3"
   },
   "source": [
    "### Feature Outliers \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4Sp5SYe8g_Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6qUPkzRN5D4"
   },
   "source": [
    "## Assumptions <a id='assumptions'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaEb4apWN5D4"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmuI_mep8g_b"
   },
   "source": [
    "# Model Preparations <a id='model-preparations'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxBwihRyOfZY"
   },
   "source": [
    "What methods did you use (or not) to solve the problem?\n",
    "\n",
    "Why are the methods you chose appropriate given the business objective?\n",
    "\n",
    "How did you decide your approach was useful?  If more than one method, which one was better or why are each better or not?\n",
    "\n",
    "What evaluation smetrics are most useful given the problem is a binary classification (ex. accuracy, f1-score, precision, recall AUC, etc)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnCsXV_c8g_V"
   },
   "source": [
    "## Sampling & Scaling Data <a id='sampling-scaling-data' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXqoLTm_8g_c"
   },
   "source": [
    "## Proposed Method <a id='proposed-metrics' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lLPX93kN5D6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT4eeZsX8g_c"
   },
   "source": [
    "## Evaluation Metrics <a id='evaluation-metrics' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGvfqpC4N5D6"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeWgSmQW8g_Z"
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUpR8S0tN5D7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul4ybaieN5D7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rADZ1qTz8g_c"
   },
   "source": [
    "## Feature Selection <a id='feature-selection' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w459qqI-N5D7"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lfHYitKN5D7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuRjMsjg8g_d"
   },
   "source": [
    "# Model Building & Evaluations <a id='model-building'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIef6T0FPIVM"
   },
   "source": [
    "Primary task is buiding a logistic regression to predict hospital readmittances.\n",
    "\n",
    "How did you handle missing values?\n",
    "\n",
    "Specify your sampling methodology\n",
    "\n",
    "Set up your models - highlights of any important parameters\n",
    "\n",
    "Analysis of your models performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dependant_and_independant_variables(df: pd.DataFrame, y_var: str):\n",
    "    X = df.copy()\n",
    "    y = X[y_var]\n",
    "    X = X.drop([y_var], axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split(X, y, test_size, random_state):\n",
    "    stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    for train_index, test_index in stratified_shuffle_split.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_dependant_and_independant_variables(df, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = shuffle_split(X, y, test_size=0.3, random_state=12343)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team drew inspriation from https://towardsdatascience.com/training-a-naive-bayes-model-to-identify-the-author-of-an-email-or-document-17dc85fa630a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_Class=pd.value_counts(df[\"spam\"], sort= True)\n",
    "count_Class.plot(kind= 'bar', color= [\"blue\", \"orange\"])\n",
    "plt.title('Bar chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subject_train = vectorizer.fit_transform(X_train['clean_subject'])\n",
    "features_subject_test = vectorizer.transform(X_test['clean_subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6547x6105 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 37731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_subject_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_body_train = vectorizer.fit_transform(X_train['clean_body'])\n",
    "features_body_test = vectorizer.transform(X_test['clean_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6547x84850 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 974741 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_body_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "features_joined_train = sparse.hstack((features_subject_train, features_body_train), format='csr') \n",
    "features_joined_test = sparse.hstack((features_subject_test, features_body_test), format='csr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6547x90955 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1012472 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_joined_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Only need 1% (or less) of the features to predict spam without overfitting.  This runs really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(f_classif, percentile=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(features_subject_train, y_train)\n",
    "features_subject_train_sel = selector.transform(features_subject_train).toarray()\n",
    "features_subject_test_sel = selector.transform(features_subject_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6547, 62)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_subject_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(features_body_train, y_train)\n",
    "features_body_train_sel = selector.transform(features_body_train).toarray()\n",
    "features_body_test_sel = selector.transform(features_body_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6547, 848)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_body_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(features_joined_train, y_train)\n",
    "features_joined_train_sel = selector.transform(features_joined_train).toarray()\n",
    "features_joined_test_sel = selector.transform(features_joined_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6547, 910)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_joined_train_sel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.743505\n",
       "1    0.256495\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline accuracy of 74% with class imbalance\n",
    "df['spam'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject Accuracy: 0.9761722926531236\n",
      "Test Subject Accuracy: 0.9237348538845331\n"
     ]
    }
   ],
   "source": [
    "# All subject features - overfits training set by 5.5%\n",
    "model1a = GaussianNB()\n",
    "features_subject_train1 = features_subject_train.toarray()\n",
    "features_subject_test1 = features_subject_test.toarray()\n",
    "model1a.fit(features_subject_train1, y_train)\n",
    "score_train = model1a.score(features_subject_train1, y_train)\n",
    "score_test = model1a.score(features_subject_test1, y_test)\n",
    "print(\"Train Subject Accuracy:\", score_train)\n",
    "print(\"Test Subject Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject Accuracy: 0.8312204062929586\n",
      "Test Subject Accuracy: 0.8296507483962936\n"
     ]
    }
   ],
   "source": [
    "# 1% of subject features - no overfitting\n",
    "model1b = GaussianNB()\n",
    "model1b.fit(features_subject_train_sel, y_train)\n",
    "score_train = model1b.score(features_subject_train_sel, y_train)\n",
    "score_test = model1b.score(features_subject_test_sel, y_test)\n",
    "print(\"Train Subject Accuracy:\", score_train)\n",
    "print(\"Test Subject Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1% of body features\n",
    "model2 = GaussianNB()\n",
    "model2.fit(features_body_train_sel, y_train)\n",
    "score_train = model2.score(features_body_train_sel, y_train)\n",
    "score_test = model2.score(features_body_test_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Body Score: 0.9596761875668245\n",
      "Test Body Score: 0.9490377761938703\n"
     ]
    }
   ],
   "source": [
    "# overfits training set by just 1% accuracy\n",
    "print(\"Train Body Score:\", score_train)\n",
    "print(\"Test Body Score:\", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Body Score: 0.9225599511226515\n",
      "Test Body Score: 0.9215965787598004\n"
     ]
    }
   ],
   "source": [
    "# 0.1% of body features\n",
    "selector = SelectPercentile(f_classif, percentile=0.1)\n",
    "selector.fit(features_body_train, y_train)\n",
    "features_body_train_sel = selector.transform(features_body_train).toarray()\n",
    "features_body_test_sel = selector.transform(features_body_test).toarray()\n",
    "model2b = GaussianNB()\n",
    "model2b.fit(features_body_train_sel, y_train)\n",
    "score_train = model2b.score(features_body_train_sel, y_train)\n",
    "score_test = model2b.score(features_body_test_sel, y_test)\n",
    "print(\"Train Body Score:\", score_train)\n",
    "print(\"Test Body Score:\", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st percentile of subject + body features\n",
    "model3 = GaussianNB()\n",
    "model3.fit(features_joined_train_sel, y_train)\n",
    "score_train = model3.score(features_joined_train_sel, y_train)\n",
    "score_test = model3.score(features_joined_test_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Body Score: 0.9601344127081106\n",
      "Test Body Score: 0.9493941553813258\n"
     ]
    }
   ],
   "source": [
    "# overfits training set by just 1%\n",
    "print(\"Train Body Score:\", score_train)\n",
    "print(\"Test Body Score:\", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Body Score: 0.9230181762639377\n",
      "Test Body Score: 0.9215965787598004\n"
     ]
    }
   ],
   "source": [
    "# 0.1% of subject + body features, similar to body only, not worth the complexity\n",
    "selector = SelectPercentile(f_classif, percentile=0.1)\n",
    "selector.fit(features_joined_train, y_train)\n",
    "features_joined_train_sel = selector.transform(features_joined_train).toarray()\n",
    "features_joined_test_sel = selector.transform(features_joined_test).toarray()\n",
    "model2b = GaussianNB()\n",
    "model2b.fit(features_joined_train_sel, y_train)\n",
    "score_train = model2b.score(features_joined_train_sel, y_train)\n",
    "score_test = model2b.score(features_joined_test_sel, y_test)\n",
    "print(\"Train Body Score:\", score_train)\n",
    "print(\"Test Body Score:\", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU9VF8AM8g_d"
   },
   "source": [
    "## Sampling Methodology <a id='sampling-methodology'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu8uewjVN5D8"
   },
   "source": [
    "#### Per the code above we used a 70/30 train test sample split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDVXhO8F8g_d",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-C7Tc5W8g_e"
   },
   "source": [
    "## Model's Performance Analysis <a id='performance-analysis'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1QaouAiN5D9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HISQa9FO8g_e"
   },
   "source": [
    "# Model Interpretability & Explainability <a id='model-explanation'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rlSakuzPhjw"
   },
   "source": [
    "Which variables were more important and why?\n",
    "\n",
    "How did you come to the conclusion these variables were important how how should the audience interpret this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSBc4ETe8g_e"
   },
   "source": [
    "## Examining Feature Importance <a id='examining-feature-importance'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpGIwvaMQD8M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb4q1PtqN5D9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLbI9bVy8g_e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbAhMB1x8g_e"
   },
   "source": [
    "# Conclusion <a id='conclusion'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fetUVJsePwN7"
   },
   "source": [
    "What are you proposing to the audience with your models and why?\n",
    "\n",
    "How should your audience interpret your conclusion and whwere should they go moving forward on the topic?\n",
    "\n",
    "What other approaches do you recommend exploring?\n",
    "\n",
    "Bring it all home!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnsadV7M8g_e"
   },
   "source": [
    "### Final Model Proposal <a id='final-model-proposal'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XXMCBozN5D-"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX8fXYczN5D-"
   },
   "source": [
    "### Future Considerations and Model Enhancements <a id='model-enhancements'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzeTkIEWN5D-"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Thch7JfCN5D_"
   },
   "source": [
    "### Alternative Modeling Approaches <a id='alternative-modeling-approaches'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUpUUjATN5D_"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Case_Study_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
