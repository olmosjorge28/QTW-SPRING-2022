{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoCXzNvN8g-8"
   },
   "source": [
    "# Case Study 3 - Email Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBy24RcB8g-9"
   },
   "source": [
    "__Team Members:__ Amber Clark, Andrew Leppla, Jorge Olmos, Paritosh Rai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4O0up-U8g-9"
   },
   "source": [
    "# Content\n",
    "* [Business Understanding](#business-understanding)\n",
    "    - [Scope](#scope)\n",
    "    - [Introduction](#introduction)\n",
    "    - [Methods](#methods)\n",
    "    - [Results](#results)\n",
    "* [Data Evaluation](#data-evaluation)\n",
    "    - [Loading Data](#loading-data) \n",
    "    - [Data Summary](#data-summary)\n",
    "    - [Missing Values](#missing-values)\n",
    "    - [Exploratory Data Analysis (EDA)](#eda)\n",
    "    - [Assumptions](#assumptions)\n",
    "* [Model Preparations](#model-preparations)\n",
    "    - [Proposed Method](#proposed-metrics)\n",
    "    - [Evaluation Metrics](#evaluation-metrics)\n",
    "    - [Feature Selection](#feature-selection)\n",
    "* [Model Building & Evaluations](#model-building)\n",
    "    - [Sampling Methodology](#sampling-methodology)\n",
    "    - [Model](#model)\n",
    "    - [Performance Analysis](#performance-analysis)\n",
    "* [Model Interpretability & Explainability](#model-explanation)\n",
    "    - [Examining Feature Importance](#examining-feature-importance)\n",
    "* [Conclusion](#conclusion)\n",
    "    - [Final Model Proposal](#final-model-proposal)\n",
    "    - [Future Considerations and Model Enhancements](#model-enhancements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRedT-FB8g_A"
   },
   "source": [
    "# Business Understanding & Executive Summary <a id='business-understanding'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-4BiuuQOEh4"
   },
   "source": [
    "This case study involves a text analysis of several thousand emails to create a model that identifies spam. The final model uses a Naïve Bayes classification method to quickly identify spam with approximately 97% accuracy, 93% F1, and __XXXX__ seconds processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction <a id='introduction'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam is a term for unsolicited email (and now other forms of messaging) that has plagued inboxes for virtually as long as email has existed. The spam originated from a song in Monty Python's Flying Circus with the lyric, \"Spam spam spam spam, spam spam spam spam, lovely spam, wonderful spam.\" In this scene, a group of Vikings in a cafe are singing about the ubiquity of the canned meat product after World War II. [1]. The term fits well to describe the potentially overwhelming pervasive presence of these unwanted and often malicious emails.\n",
    "\n",
    "According to spamlaws.com [2], 14.5 billion messages globally per day, i.e., approximately 45% of all emails (or more according to certain research firms) are considered spam. The United States is the number one generator of spam emails. The types of spam range from relatively harmless but annoying advertising (36%), some attempt to gather sensitive personal information, to malware that can install critically harmful programs capable of crashing networks or stealing data. Email filters designed to block or delete spam are essential and constantly tested by those trying to penetrate the inboxes of business and personal accounts over the globe. Even with these security measures in place, some research firms estimate that the annual losses due to productivity interruption and technical expenses to deal with spam amount to over $20 billion [2].\n",
    "\n",
    "The case study analysis examines thousands of sample emails that have been identified as either everyday correspondence(ham) or spam and attempts to build a model that can classify the emails correctly using the email sample provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods <a id='methods'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling\n",
    "Data was provided in five (5) folders containing email text – spam, spam_2, easy_ham, easy_ham2, and hard_ham – to extract the information and construct the dataset that can be leveraged to identify the spam emails. Extracted features included: folder name (folder), mail originator (from), email subject (subject), and main message (body). \n",
    "\n",
    "To make the data more manageable and processable, data cleaning was carried out to remove html and xml tags, unwanted characters, and null/empty values (NaN) from the subject and main text. Data was split in training and test sets in a 70/30 ratio, respectively. Care was taken to manage the imbalance ratio of spam and ham in training and test sets. \n",
    "\n",
    "#### NLP and Naive Bayes\n",
    "Data was processed using TFIDF (Term Frequency Inverse Data Frequency) to quantify and determine the rare words across the spam and ham emails in the training set for email body and subject. Gaussian Naive Bayes (GaussianNB) was used to build the model. Predicted outcomes of the train and test data set were compared with the actual outcomes.\n",
    "\n",
    "The team decided to use NLP (Natural Language Processing) to read and identify the text in the email subject and body. Team performed cleanup efforts on unstructured text data and removed unwanted characters and symbols to create a structured alphanumeric data frame. \n",
    "\n",
    "The Naïve Bayes algorithm was used to classify the data. This classification technique works well when features predicting the target classification are assumed to be independent of each other, and it is a proven method for effectively classifying spam.  \n",
    "#### DBSCAN\n",
    "Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm was used to find associations and structures in the data that are challenging to find manually but are relevant and valuable to find patterns and predict trends. DBSCAN groups the data points close to each other based on the density and distance measured. It also identifies the outliers in low-density regions. In the case of email, it was able to identify closely related words and separate the noise or irrelevant words. This algorithm effectively manages outliers by detecting them and considering them as non-clusters (not able to cluster them). DBSCAN allows for easy execution of various distance measures. Cosine distance (1 - cosine similarity) measures the relationship of the angle between vectors, i.e., two overlapping vectors will have minimum values. Cosine distance works excellent with text. \n",
    "\n",
    "#### Metrics\n",
    "The metrics used to evaluate model performance were accuracy, F1, and time to process. Time to process the emails was also considered an essential factor since spam should be predicted in real time. So, the team had to find the right balance between the three legs of stool (accuracy, F1, and time to process).  \n",
    "\n",
    "By maximizing the F1 score, the model balances both recall and precision for the positive class to ensure right balance is achieved to minimize the ham being identified as Spam and Spam as ham as both can create challenge.   \n",
    "\n",
    "##### Accuracy\n",
    "\n",
    "Accuracy refers to the level of agreement between the actual measurement and the predicted value.\n",
    "\n",
    "##### F1\n",
    "\n",
    "F1 values depend on Precision and Recall. Precision and recall are useful metrics when the classes are imbalanced like in this dataset. These metrics are defined as follows:\n",
    "\n",
    "Recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "\n",
    "Where:\n",
    "\n",
    "- True Positive (TP) is \"email is correctly predicted to be spam\". These predictions will correctly identify spam mail.\n",
    "- False Negative (FN) is \"email is incorrectly predicting ham to be spam\". These predictions would predict ham as spam.\n",
    "- False Positive (FP) is \"email is incorrectly predicting ham to be spam\". These predictions would identify ham as spam.\n",
    "\n",
    "Both Recall and Precision focus the modeling on True Positives, but Recall is penalized by False Negatives whereas Precision is penalized by False Positives. \n",
    "\n",
    "To balance both precision and recall, the team used the F1 score. The F1 score combines precision and recall into a single metric by taking their harmonic mean:\n",
    "\n",
    "F1 = 2 * Recall * Precision / (Recall + Precision)\n",
    "\n",
    "In the absence of stakeholder guidance, the team chose this balanced approach to misclassification.  \n",
    "\n",
    "##### Processing Time\n",
    "The time to process the email is calculated for each model. The team tuned the number of features in the Naïve Bayes model to optimize the processing time and prevent over fitting.\n",
    "\n",
    "#### Modeling Objective\n",
    "\n",
    "The team's objective was to maximize __accuracy__ and __F1__ while minimizing the __processing time__ to make predictions in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results <a id='results'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model had an accuracy of 97%, F1-score of 93%, and processing time* of __XXX__ seconds (so fast!).  This model used only 5% of the features from the email subject+body with __XXXX__ total features.\n",
    "\n",
    "*processing time depends on the machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type         | Percentile | No of Features | Train Accuracy | Test Accuracy | f1-score | Processing Time |\n",
    "|--------------|------------|----------------|----------------|---------------|----------|-----------------|\n",
    "| body         | 100        | 77396          | 0.95           | 0.93          | 0.83     | 7.9631          |\n",
    "| subject      | 100        | 6086           | 0.96           | 0.92          | 0.81     | 0.8683          |\n",
    "| subject      | 1          | 59             | 0.8            | 0.8           | 0.37     | 0.0195          |\n",
    "| body         | 1          | 773            | 0.94           | 0.93          | 0.85     | 0.0861          |\n",
    "| body         | 0.1        | 78             | 0.83           | 0.83          | 0.52     | 0.0175          |\n",
    "| __subject+body__ | __1__          | __832__            | __0.94__           | __0.94__          | __0.88__     | __0.103__           |\n",
    "| subject+body | 0.1        | 84             | 0.84           | 0.84          | 0.55     | 0.0138          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVtcYu5j8g_B"
   },
   "source": [
    "# Data Engineering <a id='data-evaluation'>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was provided in five (5) folders containing email text – spam, spam_2, easy_ham, easy_ham2, and hard_ham – to extract the information to construct the dataset that can be leveraged to identify the spam emails. Empty email data frame was created with folder name (folder), mail originator (from), email subject (subject), and main message (body). Email from the five (5) folders listed above was extracted and parsed under the respective column into the email data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qcBcP8Jy8g_C",
    "outputId": "a6a85b4a-a106-48bb-bc2a-e6a5fb8ca494"
   },
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Image\n",
    "import sklearn\n",
    "import time\n",
    "# email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tabulate import tabulate\n",
    "\n",
    "# data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from statistics import stdev\n",
    "\n",
    "# prediction models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import warnings filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WcvKI3y8g_C"
   },
   "source": [
    "### Loading Data and Cleanup <a id='loading-data'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDhb7boF8g_D"
   },
   "source": [
    "As part of data cleanup, team removed HTML tags, stop words, and non-alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3dYvb9W38g_D",
    "outputId": "3a6b397c-92dc-4ce0-c599-9cf69191e676"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_path = os.path.abspath('ds7333_case_study_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_spam = os.path.join(os.path.dirname(notebook_path), \"SpamAssassinMessages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(folder):\n",
    "    file_list = []\n",
    "    if os.path.exists(folder):\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root,file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(file_spam)\n",
    "# Get the file names in each folder (list of lists)\n",
    "files = [ os.listdir(file_spam+ '/'+ folder) for folder in folders] \n",
    "\n",
    "# Create a list of dataframes for all of the folders\n",
    "emails = [ pd.DataFrame({'folder' : [], 'from' : [], 'subject' : [], 'body': []}) ]*len(folders)\n",
    "\n",
    "# Add folder path to file names\n",
    "for i in range(0,len(folders)):\n",
    "    for j in range(0, len(files[i])):\n",
    "        files[i][j] = str(file_spam +'/' + folders[i] + '/' + files[i][j]) \n",
    "        \n",
    "        # Parse and extract email 'subject' and 'from'\n",
    "        with open(files[i][j], 'rb') as fp:\n",
    "            msg = BytesParser(policy=policy.default).parse(fp)\n",
    "            \n",
    "            # Error checking when reading in body for some html-based emails from spam folders\n",
    "            try:\n",
    "                simplest = msg.get_body(preferencelist=('plain', 'html'))\n",
    "                try:\n",
    "                    new_row = {'folder': folders[i], 'from': msg['from'], 'subject': msg['subject'], 'body': simplest.get_content()}\n",
    "                    emails[i] = emails[i].append(new_row, ignore_index=True)\n",
    "                except:\n",
    "                    new_row = {'folder': folders[i], 'from': msg['from'], 'subject':msg['subject'], 'body':'Error(html)'}\n",
    "                    emails[i] = emails[i].append(new_row, ignore_index=True)\n",
    "            except:\n",
    "                new_row = {'folder': folders[i], 'from': msg['from'], 'subject':msg['subject'], 'body':'Error(html)'}\n",
    "                emails[i] = emails[i].append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# files in folders: [5052, 1401, 501, 1001, 1398]\n",
      "# emails read in  : [5052, 1401, 501, 1001, 1398]\n",
      "\n",
      "# total emails = 9353\n"
     ]
    }
   ],
   "source": [
    "# Emails per folder\n",
    "print(\"# files in folders:\", [len(i) for i in files])\n",
    "print(\"# emails read in  :\", [i.shape[0] for i in emails])\n",
    "\n",
    "# Total emails\n",
    "print( \"\\n# total emails =\", sum([len(i) for i in files]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9353, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create single dataframe from all folders\n",
    "df = pd.concat( [emails[i] for i in range(0, len(emails))], axis=0)\n",
    "\n",
    "#  Keep the indices from the folders\n",
    "df = df.reset_index() \n",
    "\n",
    "# create response column from folder names\n",
    "spam = [(i=='spam' or i=='spam_2') for i in df['folder']]\n",
    "df = pd.concat([df, pd.Series(spam).astype(int)], axis=1)\n",
    "\n",
    "df.columns = ['folder_idx', 'folder', 'from', 'subject', 'body','spam']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_regex = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(html_regex, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAndSplit(raw_text): \n",
    "    temp = []\n",
    "    for word in raw_text.split():\n",
    "        temp.append(re.sub(r\"[^a-zA-Z0-9]\",\"\",word).lower())\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanBody(raw_content):\n",
    "    if(pd.isna(raw_content)):\n",
    "        return []\n",
    "    clean_from_html = cleanhtml(raw_content)\n",
    "    out = cleanAndSplit(clean_from_html)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(content):\n",
    "    joined = np.concatenate((*content[['clean_body']], *content[['clean_subject']]))\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_body'] = df['body'].apply(cleanBody)\n",
    "df['clean_subject'] = df['subject'].apply(cleanBody)\n",
    "df['joined'] = df[['clean_body','clean_subject']].agg(combine, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_idx</th>\n",
       "      <th>folder</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Robert Elz &lt;kre@munnari.OZ.AU&gt;</td>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -05...</td>\n",
       "      <td>0</td>\n",
       "      <td>[date, wed, 21, aug, 2002, 105446, 0500, from,...</td>\n",
       "      <td>[re, new, sequences, window]</td>\n",
       "      <td>[date, wed, 21, aug, 2002, 105446, 0500, from,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Steve Burt &lt;Steve_Burt@cursor-system.com&gt;</td>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>[martin, a, posted, tassos, papadopoulos, the,...</td>\n",
       "      <td>[zzzzteana, re, alexander]</td>\n",
       "      <td>[martin, a, posted, tassos, papadopoulos, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Tim Chapman &lt;timc@2ubh.com&gt;</td>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>0</td>\n",
       "      <td>[man, threatens, explosion, in, moscow, thursd...</td>\n",
       "      <td>[zzzzteana, moscow, bomber]</td>\n",
       "      <td>[man, threatens, explosion, in, moscow, thursd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Monty Solomon &lt;monty@roscom.com&gt;</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>0</td>\n",
       "      <td>[klez, the, virus, that, wont, die, already, t...</td>\n",
       "      <td>[irr, klez, the, virus, that, wont, die]</td>\n",
       "      <td>[klez, the, virus, that, wont, die, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>Stewart Smith &lt;Stewart.Smith@ee.ed.ac.uk&gt;</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[, in, adding, cream, to, spaghetti, carbonara...</td>\n",
       "      <td>[re, zzzzteana, nothing, like, mama, used, to,...</td>\n",
       "      <td>[, in, adding, cream, to, spaghetti, carbonara...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder_idx    folder                                       from  \\\n",
       "0           0  easy_ham             Robert Elz <kre@munnari.OZ.AU>   \n",
       "1           1  easy_ham  Steve Burt <Steve_Burt@cursor-system.com>   \n",
       "2           2  easy_ham                Tim Chapman <timc@2ubh.com>   \n",
       "3           3  easy_ham           Monty Solomon <monty@roscom.com>   \n",
       "4           4  easy_ham  Stewart Smith <Stewart.Smith@ee.ed.ac.uk>   \n",
       "\n",
       "                                          subject  \\\n",
       "0                        Re: New Sequences Window   \n",
       "1                       [zzzzteana] RE: Alexander   \n",
       "2                       [zzzzteana] Moscow bomber   \n",
       "3           [IRR] Klez: The Virus That  Won't Die   \n",
       "4  Re: [zzzzteana] Nothing like mama used to make   \n",
       "\n",
       "                                                body  spam  \\\n",
       "0      Date:        Wed, 21 Aug 2002 10:54:46 -05...     0   \n",
       "1  Martin A posted:\\nTassos Papadopoulos, the Gre...     0   \n",
       "2  Man Threatens Explosion In Moscow \\n\\nThursday...     0   \n",
       "3  Klez: The Virus That Won't Die\\n \\nAlready the...     0   \n",
       "4  >  in adding cream to spaghetti carbonara, whi...     0   \n",
       "\n",
       "                                          clean_body  \\\n",
       "0  [date, wed, 21, aug, 2002, 105446, 0500, from,...   \n",
       "1  [martin, a, posted, tassos, papadopoulos, the,...   \n",
       "2  [man, threatens, explosion, in, moscow, thursd...   \n",
       "3  [klez, the, virus, that, wont, die, already, t...   \n",
       "4  [, in, adding, cream, to, spaghetti, carbonara...   \n",
       "\n",
       "                                       clean_subject  \\\n",
       "0                       [re, new, sequences, window]   \n",
       "1                         [zzzzteana, re, alexander]   \n",
       "2                        [zzzzteana, moscow, bomber]   \n",
       "3           [irr, klez, the, virus, that, wont, die]   \n",
       "4  [re, zzzzteana, nothing, like, mama, used, to,...   \n",
       "\n",
       "                                              joined  \n",
       "0  [date, wed, 21, aug, 2002, 105446, 0500, from,...  \n",
       "1  [martin, a, posted, tassos, papadopoulos, the,...  \n",
       "2  [man, threatens, explosion, in, moscow, thursd...  \n",
       "3  [klez, the, virus, that, wont, die, already, t...  \n",
       "4  [, in, adding, cream, to, spaghetti, carbonara...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aws5HAx98g_E"
   },
   "source": [
    "## Missing Values <a id='missing-values'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 12 emails with missing subjects.  In addition, 33 of approximately 9,000 emails (less than .5%) that the team was not able to read in for modeling and analysis.  These 33 emails were a small subset of the html emails.  Missing values were replaced with \"No Subject\" for subject and \"Error(html)\" for body.  A missing subject is important to identify spam emails, and these complicated html emails were also all spam.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2BgB13po8g_F",
    "outputId": "aba28207-2ccb-4d38-b36a-adcd6d28dd45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_idx</th>\n",
       "      <th>folder</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>237</td>\n",
       "      <td>spam</td>\n",
       "      <td>eb@via.ecp.fr</td>\n",
       "      <td>Over $100,000 Per Year Possible On The Net!  N...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[over, 100000, per, year, possible, on, the, n...</td>\n",
       "      <td>[errorhtml, over, 100000, per, year, possible,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>349</td>\n",
       "      <td>spam</td>\n",
       "      <td>\"Books@Books\"@BlackRealityPublishing.com</td>\n",
       "      <td>Free Excerpt;  Baby Makers, Loser Choosers, &amp; ...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[free, excerpt, baby, makers, loser, choosers,...</td>\n",
       "      <td>[errorhtml, free, excerpt, baby, makers, loser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>425</td>\n",
       "      <td>spam</td>\n",
       "      <td>zzzz@netscape.net</td>\n",
       "      <td>Collect Your Money! Time:1:30:33 AM</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[collect, your, money, time13033, am]</td>\n",
       "      <td>[errorhtml, collect, your, money, time13033, am]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>512</td>\n",
       "      <td>spam</td>\n",
       "      <td>Affordable Computer Supply &lt;InkjetDeals@acsmsu...</td>\n",
       "      <td>Printer Cartridges as low as $1.21 each!</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[printer, cartridges, as, low, as, 121, each]</td>\n",
       "      <td>[errorhtml, printer, cartridges, as, low, as, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7679</th>\n",
       "      <td>725</td>\n",
       "      <td>spam</td>\n",
       "      <td>eb@via.ecp.fr</td>\n",
       "      <td>Over $100,000 Per Year Possible On The Net!  N...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[over, 100000, per, year, possible, on, the, n...</td>\n",
       "      <td>[errorhtml, over, 100000, per, year, possible,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>828</td>\n",
       "      <td>spam</td>\n",
       "      <td>\"Books@Books\"@BlackRealityPublishing.com</td>\n",
       "      <td>Free Excerpt;  Baby Makers, Loser Choosers, &amp; ...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[free, excerpt, baby, makers, loser, choosers,...</td>\n",
       "      <td>[errorhtml, free, excerpt, baby, makers, loser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>898</td>\n",
       "      <td>spam</td>\n",
       "      <td>zzzz@netscape.net</td>\n",
       "      <td>Collect Your Money! Time:1:30:33 AM</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[collect, your, money, time13033, am]</td>\n",
       "      <td>[errorhtml, collect, your, money, time13033, am]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>977</td>\n",
       "      <td>spam</td>\n",
       "      <td>Affordable Computer Supply &lt;InkjetDeals@acsmsu...</td>\n",
       "      <td>Printer Cartridges as low as $1.21 each!</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[printer, cartridges, as, low, as, 121, each]</td>\n",
       "      <td>[errorhtml, printer, cartridges, as, low, as, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>1</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>lmrn@mailexcite.com</td>\n",
       "      <td>Real Protection, Stun Guns!  Free Shipping! Ti...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[real, protection, stun, guns, free, shipping,...</td>\n",
       "      <td>[errorhtml, real, protection, stun, guns, free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>2</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>amknight@mailexcite.com</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[new, improved, fat, burners, now, with, tv, f...</td>\n",
       "      <td>[errorhtml, new, improved, fat, burners, now, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>3</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>jordan23@mailexcite.com</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[new, improved, fat, burners, now, with, tv, f...</td>\n",
       "      <td>[errorhtml, new, improved, fat, burners, now, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7959</th>\n",
       "      <td>4</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>Never Repay Cash Grants, $500 - $50,000, Secre...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[never, repay, cash, grants, 500, , 50000, sec...</td>\n",
       "      <td>[errorhtml, never, repay, cash, grants, 500, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7960</th>\n",
       "      <td>5</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>3b3fke@ms10.hinet.net</td>\n",
       "      <td>�٦b��20%���H�Υd�`����??? Time:PM 05:36:34</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[b20hd, timepm, 053634]</td>\n",
       "      <td>[errorhtml, b20hd, timepm, 053634]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>105</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>Mary &lt;jane0l215@excite.com&gt;</td>\n",
       "      <td>Major Stock Play</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[major, stock, play]</td>\n",
       "      <td>[errorhtml, major, stock, play]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>107</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>Mary &lt;jane0l215@excite.com&gt;</td>\n",
       "      <td>Major Stock Play</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[major, stock, play]</td>\n",
       "      <td>[errorhtml, major, stock, play]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>203</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>iqsoftware@export2000.ro</td>\n",
       "      <td>[Avfs] Romanian Software Production &amp; Export</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[avfs, romanian, software, production, , export]</td>\n",
       "      <td>[errorhtml, avfs, romanian, software, producti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>292</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>Polaroid@optinat.com</td>\n",
       "      <td>Polariod Digital Cameras Only $39.95</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[polariod, digital, cameras, only, 3995]</td>\n",
       "      <td>[errorhtml, polariod, digital, cameras, only, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>323</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>merchantsworld2001@juno.com</td>\n",
       "      <td>New Improved Weight Loss, Now With Bonus Fat A...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[new, improved, weight, loss, now, with, bonus...</td>\n",
       "      <td>[errorhtml, new, improved, weight, loss, now, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8306</th>\n",
       "      <td>351</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>WEBMASTER@J-MEDICAL.ORG</td>\n",
       "      <td>Re: Account Information</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[re, account, information]</td>\n",
       "      <td>[errorhtml, re, account, information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>379</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>Matthew_Morrow@optinunlimited.com</td>\n",
       "      <td>About Your Commissions...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[about, your, commissions]</td>\n",
       "      <td>[errorhtml, about, your, commissions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>394</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>rose_xu@email.com</td>\n",
       "      <td>ADV:Harvest lots of Target Email address quickly</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[advharvest, lots, of, target, email, address,...</td>\n",
       "      <td>[errorhtml, advharvest, lots, of, target, emai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>408</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>Prosextra@optinunlimited.com</td>\n",
       "      <td>FREE ALL NATURAL SEXUAL STIMULANT!</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[free, all, natural, sexual, stimulant]</td>\n",
       "      <td>[errorhtml, free, all, natural, sexual, stimul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>477</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>WEBMASTER@theperfumebox.ie</td>\n",
       "      <td>Re: Account Information</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[re, account, information]</td>\n",
       "      <td>[errorhtml, re, account, information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>570</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>WEBMASTER@TAIONE.ORG</td>\n",
       "      <td>Re: Your Order</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[re, your, order]</td>\n",
       "      <td>[errorhtml, re, your, order]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>576</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>targetemailextractor@btamail.net.cn</td>\n",
       "      <td>Direct Email Blaster, Email extractor, email d...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[direct, email, blaster, email, extractor, ema...</td>\n",
       "      <td>[errorhtml, direct, email, blaster, email, ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>577</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>targetemailextractor@btamail.net.cn</td>\n",
       "      <td>Direct Email Blaster, Email extractor, email d...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[direct, email, blaster, email, extractor, ema...</td>\n",
       "      <td>[errorhtml, direct, email, blaster, email, ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>756</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>JohnRobertson@terra.es</td>\n",
       "      <td>Get Debts Off Your Back    -      Time:5:38:50 AM</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[get, debts, off, your, back, , time53850, am]</td>\n",
       "      <td>[errorhtml, get, debts, off, your, back, , tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>820</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>easytest8341@email.com</td>\n",
       "      <td>Your $1365 Welcome Bonus is waiting for You!!</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[your, 1365, welcome, bonus, is, waiting, for,...</td>\n",
       "      <td>[errorhtml, your, 1365, welcome, bonus, is, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8892</th>\n",
       "      <td>937</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>POWERMAN10MILLION@hotmail.com</td>\n",
       "      <td>10 million fresh email addresses sent to you o...</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[10, million, fresh, email, addresses, sent, t...</td>\n",
       "      <td>[errorhtml, 10, million, fresh, email, address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>979</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>Central_Bank6@centralbank.com</td>\n",
       "      <td>Notification for Payment Received!</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[notification, for, payment, received]</td>\n",
       "      <td>[errorhtml, notification, for, payment, received]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>1003</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>ankara@dunyagazetesi.com.tr</td>\n",
       "      <td>Kime Oy Vereceksiniz ?</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[kime, oy, vereceksiniz, ]</td>\n",
       "      <td>[errorhtml, kime, oy, vereceksiniz, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>1210</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>\"Com-Pro Systems, Inc.\" &lt;emarketing@comprosys....</td>\n",
       "      <td>Get Your Own Great-Looking Website</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[get, your, own, greatlooking, website]</td>\n",
       "      <td>[errorhtml, get, your, own, greatlooking, webs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>1216</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>webmaster@efi.joensuu.fi</td>\n",
       "      <td>Collect Your Money! Time:12:13:18 AM</td>\n",
       "      <td>Error(html)</td>\n",
       "      <td>1</td>\n",
       "      <td>[errorhtml]</td>\n",
       "      <td>[collect, your, money, time121318, am]</td>\n",
       "      <td>[errorhtml, collect, your, money, time121318, am]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      folder_idx  folder                                               from  \\\n",
       "7191         237    spam                                      eb@via.ecp.fr   \n",
       "7303         349    spam           \"Books@Books\"@BlackRealityPublishing.com   \n",
       "7379         425    spam                                  zzzz@netscape.net   \n",
       "7466         512    spam  Affordable Computer Supply <InkjetDeals@acsmsu...   \n",
       "7679         725    spam                                      eb@via.ecp.fr   \n",
       "7782         828    spam           \"Books@Books\"@BlackRealityPublishing.com   \n",
       "7852         898    spam                                  zzzz@netscape.net   \n",
       "7931         977    spam  Affordable Computer Supply <InkjetDeals@acsmsu...   \n",
       "7956           1  spam_2                                lmrn@mailexcite.com   \n",
       "7957           2  spam_2                            amknight@mailexcite.com   \n",
       "7958           3  spam_2                            jordan23@mailexcite.com   \n",
       "7959           4  spam_2                                  yyyy@pluriproj.pt   \n",
       "7960           5  spam_2                              3b3fke@ms10.hinet.net   \n",
       "8060         105  spam_2                        Mary <jane0l215@excite.com>   \n",
       "8062         107  spam_2                        Mary <jane0l215@excite.com>   \n",
       "8158         203  spam_2                           iqsoftware@export2000.ro   \n",
       "8247         292  spam_2                               Polaroid@optinat.com   \n",
       "8278         323  spam_2                        merchantsworld2001@juno.com   \n",
       "8306         351  spam_2                            WEBMASTER@J-MEDICAL.ORG   \n",
       "8334         379  spam_2                  Matthew_Morrow@optinunlimited.com   \n",
       "8349         394  spam_2                                  rose_xu@email.com   \n",
       "8363         408  spam_2                       Prosextra@optinunlimited.com   \n",
       "8432         477  spam_2                         WEBMASTER@theperfumebox.ie   \n",
       "8525         570  spam_2                               WEBMASTER@TAIONE.ORG   \n",
       "8531         576  spam_2                targetemailextractor@btamail.net.cn   \n",
       "8532         577  spam_2                targetemailextractor@btamail.net.cn   \n",
       "8711         756  spam_2                             JohnRobertson@terra.es   \n",
       "8775         820  spam_2                             easytest8341@email.com   \n",
       "8892         937  spam_2                      POWERMAN10MILLION@hotmail.com   \n",
       "8934         979  spam_2                      Central_Bank6@centralbank.com   \n",
       "8958        1003  spam_2                        ankara@dunyagazetesi.com.tr   \n",
       "9165        1210  spam_2  \"Com-Pro Systems, Inc.\" <emarketing@comprosys....   \n",
       "9171        1216  spam_2                           webmaster@efi.joensuu.fi   \n",
       "\n",
       "                                                subject         body  spam  \\\n",
       "7191  Over $100,000 Per Year Possible On The Net!  N...  Error(html)     1   \n",
       "7303  Free Excerpt;  Baby Makers, Loser Choosers, & ...  Error(html)     1   \n",
       "7379                Collect Your Money! Time:1:30:33 AM  Error(html)     1   \n",
       "7466           Printer Cartridges as low as $1.21 each!  Error(html)     1   \n",
       "7679  Over $100,000 Per Year Possible On The Net!  N...  Error(html)     1   \n",
       "7782  Free Excerpt;  Baby Makers, Loser Choosers, & ...  Error(html)     1   \n",
       "7852                Collect Your Money! Time:1:30:33 AM  Error(html)     1   \n",
       "7931           Printer Cartridges as low as $1.21 each!  Error(html)     1   \n",
       "7956  Real Protection, Stun Guns!  Free Shipping! Ti...  Error(html)     1   \n",
       "7957  New Improved Fat Burners, Now With TV Fat Abso...  Error(html)     1   \n",
       "7958  New Improved Fat Burners, Now With TV Fat Abso...  Error(html)     1   \n",
       "7959  Never Repay Cash Grants, $500 - $50,000, Secre...  Error(html)     1   \n",
       "7960          �٦b��20%���H�Υd�`����??? Time:PM 05:36:34  Error(html)     1   \n",
       "8060                                   Major Stock Play  Error(html)     1   \n",
       "8062                                   Major Stock Play  Error(html)     1   \n",
       "8158       [Avfs] Romanian Software Production & Export  Error(html)     1   \n",
       "8247               Polariod Digital Cameras Only $39.95  Error(html)     1   \n",
       "8278  New Improved Weight Loss, Now With Bonus Fat A...  Error(html)     1   \n",
       "8306                            Re: Account Information  Error(html)     1   \n",
       "8334                          About Your Commissions...  Error(html)     1   \n",
       "8349   ADV:Harvest lots of Target Email address quickly  Error(html)     1   \n",
       "8363                 FREE ALL NATURAL SEXUAL STIMULANT!  Error(html)     1   \n",
       "8432                            Re: Account Information  Error(html)     1   \n",
       "8525                                     Re: Your Order  Error(html)     1   \n",
       "8531  Direct Email Blaster, Email extractor, email d...  Error(html)     1   \n",
       "8532  Direct Email Blaster, Email extractor, email d...  Error(html)     1   \n",
       "8711  Get Debts Off Your Back    -      Time:5:38:50 AM  Error(html)     1   \n",
       "8775     Your $1365 Welcome Bonus is waiting for You!!   Error(html)     1   \n",
       "8892  10 million fresh email addresses sent to you o...  Error(html)     1   \n",
       "8934                 Notification for Payment Received!  Error(html)     1   \n",
       "8958                             Kime Oy Vereceksiniz ?  Error(html)     1   \n",
       "9165                 Get Your Own Great-Looking Website  Error(html)     1   \n",
       "9171               Collect Your Money! Time:12:13:18 AM  Error(html)     1   \n",
       "\n",
       "       clean_body                                      clean_subject  \\\n",
       "7191  [errorhtml]  [over, 100000, per, year, possible, on, the, n...   \n",
       "7303  [errorhtml]  [free, excerpt, baby, makers, loser, choosers,...   \n",
       "7379  [errorhtml]              [collect, your, money, time13033, am]   \n",
       "7466  [errorhtml]      [printer, cartridges, as, low, as, 121, each]   \n",
       "7679  [errorhtml]  [over, 100000, per, year, possible, on, the, n...   \n",
       "7782  [errorhtml]  [free, excerpt, baby, makers, loser, choosers,...   \n",
       "7852  [errorhtml]              [collect, your, money, time13033, am]   \n",
       "7931  [errorhtml]      [printer, cartridges, as, low, as, 121, each]   \n",
       "7956  [errorhtml]  [real, protection, stun, guns, free, shipping,...   \n",
       "7957  [errorhtml]  [new, improved, fat, burners, now, with, tv, f...   \n",
       "7958  [errorhtml]  [new, improved, fat, burners, now, with, tv, f...   \n",
       "7959  [errorhtml]  [never, repay, cash, grants, 500, , 50000, sec...   \n",
       "7960  [errorhtml]                            [b20hd, timepm, 053634]   \n",
       "8060  [errorhtml]                               [major, stock, play]   \n",
       "8062  [errorhtml]                               [major, stock, play]   \n",
       "8158  [errorhtml]   [avfs, romanian, software, production, , export]   \n",
       "8247  [errorhtml]           [polariod, digital, cameras, only, 3995]   \n",
       "8278  [errorhtml]  [new, improved, weight, loss, now, with, bonus...   \n",
       "8306  [errorhtml]                         [re, account, information]   \n",
       "8334  [errorhtml]                         [about, your, commissions]   \n",
       "8349  [errorhtml]  [advharvest, lots, of, target, email, address,...   \n",
       "8363  [errorhtml]            [free, all, natural, sexual, stimulant]   \n",
       "8432  [errorhtml]                         [re, account, information]   \n",
       "8525  [errorhtml]                                  [re, your, order]   \n",
       "8531  [errorhtml]  [direct, email, blaster, email, extractor, ema...   \n",
       "8532  [errorhtml]  [direct, email, blaster, email, extractor, ema...   \n",
       "8711  [errorhtml]     [get, debts, off, your, back, , time53850, am]   \n",
       "8775  [errorhtml]  [your, 1365, welcome, bonus, is, waiting, for,...   \n",
       "8892  [errorhtml]  [10, million, fresh, email, addresses, sent, t...   \n",
       "8934  [errorhtml]             [notification, for, payment, received]   \n",
       "8958  [errorhtml]                         [kime, oy, vereceksiniz, ]   \n",
       "9165  [errorhtml]            [get, your, own, greatlooking, website]   \n",
       "9171  [errorhtml]             [collect, your, money, time121318, am]   \n",
       "\n",
       "                                                 joined  \n",
       "7191  [errorhtml, over, 100000, per, year, possible,...  \n",
       "7303  [errorhtml, free, excerpt, baby, makers, loser...  \n",
       "7379   [errorhtml, collect, your, money, time13033, am]  \n",
       "7466  [errorhtml, printer, cartridges, as, low, as, ...  \n",
       "7679  [errorhtml, over, 100000, per, year, possible,...  \n",
       "7782  [errorhtml, free, excerpt, baby, makers, loser...  \n",
       "7852   [errorhtml, collect, your, money, time13033, am]  \n",
       "7931  [errorhtml, printer, cartridges, as, low, as, ...  \n",
       "7956  [errorhtml, real, protection, stun, guns, free...  \n",
       "7957  [errorhtml, new, improved, fat, burners, now, ...  \n",
       "7958  [errorhtml, new, improved, fat, burners, now, ...  \n",
       "7959  [errorhtml, never, repay, cash, grants, 500, ,...  \n",
       "7960                 [errorhtml, b20hd, timepm, 053634]  \n",
       "8060                    [errorhtml, major, stock, play]  \n",
       "8062                    [errorhtml, major, stock, play]  \n",
       "8158  [errorhtml, avfs, romanian, software, producti...  \n",
       "8247  [errorhtml, polariod, digital, cameras, only, ...  \n",
       "8278  [errorhtml, new, improved, weight, loss, now, ...  \n",
       "8306              [errorhtml, re, account, information]  \n",
       "8334              [errorhtml, about, your, commissions]  \n",
       "8349  [errorhtml, advharvest, lots, of, target, emai...  \n",
       "8363  [errorhtml, free, all, natural, sexual, stimul...  \n",
       "8432              [errorhtml, re, account, information]  \n",
       "8525                       [errorhtml, re, your, order]  \n",
       "8531  [errorhtml, direct, email, blaster, email, ext...  \n",
       "8532  [errorhtml, direct, email, blaster, email, ext...  \n",
       "8711  [errorhtml, get, debts, off, your, back, , tim...  \n",
       "8775  [errorhtml, your, 1365, welcome, bonus, is, wa...  \n",
       "8892  [errorhtml, 10, million, fresh, email, address...  \n",
       "8934  [errorhtml, notification, for, payment, received]  \n",
       "8958              [errorhtml, kime, oy, vereceksiniz, ]  \n",
       "9165  [errorhtml, get, your, own, greatlooking, webs...  \n",
       "9171  [errorhtml, collect, your, money, time121318, am]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows where body couldn't be read in = 'Error(html)'\n",
    "df.loc[df['body']=='Error(html)']\n",
    "\n",
    "# All spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of body read Errors\n",
    "df.loc[df['body']=='Error(html)'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "folder_idx        0\n",
       "folder            0\n",
       "from              5\n",
       "subject          12\n",
       "body              0\n",
       "spam              0\n",
       "clean_body        0\n",
       "clean_subject     0\n",
       "joined            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN and None values with 'No Subject'\n",
    "df.loc[ df['subject'].isna(), 'subject'] = 'No Subject'\n",
    "df.loc[ df['subject']=='', 'subject'] = 'No Subject'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbAmkozvN5Dz"
   },
   "source": [
    "## Exploratory Data Analysis (EDA) <a id='eda'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_Class=pd.value_counts(df[\"spam\"], sort= True)\n",
    "count_Class.plot(kind= 'bar', color= [\"blue\", \"orange\"])\n",
    "plt.title('Counts of Spam(1) vs. Ham(0)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChoPhHdx8g_M"
   },
   "source": [
    "### Clustering\n",
    "- Use DBSCAN with cosine distance for NLP.  \n",
    "- Try to get approx. 5 clusters to dissect and explain\n",
    "- Look for descriptors for the clusters, like business vs. personal emails, IT emails, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "vectorizer = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=None, stop_words='english');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subject = vectorizer.fit_transform(df['clean_subject']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: Highlight first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EqDlP8C_N5D0",
    "outputId": "8ec90270-f4e0-4210-c59a-64c9b6deb27c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples</th>\n",
       "      <th>epsilon</th>\n",
       "      <th># clusters</th>\n",
       "      <th># pure clusters</th>\n",
       "      <th># pure emails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>125</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>125</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>125</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples  epsilon  # clusters  # pure clusters  # pure emails\n",
       "10          125     0.70           6                4            577\n",
       "2            75     0.70           8                5            571\n",
       "11          125     0.75           6                3            548\n",
       "7           100     0.75           6                3            542\n",
       "6           100     0.70           6                3            433\n",
       "0            75     0.60           4                3            327\n",
       "3            75     0.75           5                2            300\n",
       "5           100     0.65           4                2            245\n",
       "9           125     0.65           4                2            245\n",
       "4           100     0.60           3                2            242\n",
       "1            75     0.65           4                2            241\n",
       "8           125     0.60           1                1            131"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(metric='cosine', min_samples=125)\n",
    "eps_clusters = []\n",
    "\n",
    "for j in range(75,126,25):\n",
    "    dbscan.min_samples = j\n",
    "    for i in range(60,76,5):\n",
    "        dbscan.eps = i/100\n",
    "        clustering = pd.Series( dbscan.fit_predict(features_subject) )\n",
    "        \n",
    "        cluster_counts = list( clustering.value_counts().sort_index() )\n",
    "        cluster_counts.pop(0) # remove -1 cluster which is a non-cluster \n",
    "        num_clusters = len(cluster_counts)\n",
    "        \n",
    "        clustering_spam = pd.concat([clustering, df['spam']], axis=1)\n",
    "        clustering_spam.columns = ['cluster', 'spam']       \n",
    "        clustering_spam_counts = pd.DataFrame( clustering_spam.value_counts() ).reset_index()\n",
    "        cluster_purity = list( ( clustering_spam_counts[['cluster']].value_counts()==1 ).sort_index() )\n",
    "        cluster_purity.pop(0) # remove -1 cluster which is a non-cluster\n",
    "        num_pure_clusters = sum(cluster_purity)\n",
    "        num_pure_emails = sum( np.multiply(cluster_counts, cluster_purity) )\n",
    "        \n",
    "        eps_clusters.append([ dbscan.min_samples, dbscan.eps, num_clusters, num_pure_clusters, num_pure_emails])\n",
    "\n",
    "clusters_df = pd.DataFrame(eps_clusters, columns = ['min_samples','epsilon', '# clusters', '# pure clusters', '# pure emails'])\n",
    "clusters_df.sort_values(by='# pure emails', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Clusters - Insights\n",
    "\n",
    "min_samples=125, epsilon=0.70 had 4 pure clusters that contained only 'ham' emails.  These clusters could be used to filter or pre-process emails before Naive Bayes classification.  \n",
    "\n",
    "### Todo: Update cluster descriptions\n",
    "\n",
    "- Cluster 0 : News & Dates\n",
    "- Cluster 1 : Pain (ouch, hurts)\n",
    "- Cluster 2 : Unknown\n",
    "- Cluster 3 : spam\n",
    "- Cluster 4 : [Spambayes] & package\n",
    "- Cluster 5 : [zzzzteana]\n",
    "\n",
    "min_samples could be decreased to 50 or less which would give more pure emails but many more clusters to explore and manage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head & tail of each cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>subject</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>[use Perl] Headlines for 2002-08-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>NTK Now, 2002-08-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>[use Perl] Headlines for 2002-10-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0</td>\n",
       "      <td>[use Perl] Stories for 2002-08-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6661</th>\n",
       "      <td>0</td>\n",
       "      <td>[use Perl] Stories for 2002-08-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>0</td>\n",
       "      <td>[use Perl] Stories for 2002-08-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: \"Ouch. Ouch. Ouch. Ouch. Ouch....\"(was Re:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: \"Ouch. Ouch. Ouch. Ouch. Ouch....\"(was Re:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1</td>\n",
       "      <td>Ouch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: My brain hurts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>1</td>\n",
       "      <td>Re[3]: Forged whitelist spam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: Re[3]: Forged whitelist spam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>Re: [SAtalk] O.T. Habeus -- Why?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2</td>\n",
       "      <td>[zzzzteana] \"Put this in your stereo and smoke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>2</td>\n",
       "      <td>Re: [SAtalk] O.T. Habeus -- Why?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>2</td>\n",
       "      <td>-- USA Business Search CD --</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>2</td>\n",
       "      <td>** You're -Approved-! **</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>2</td>\n",
       "      <td>yyyy Your computer can READ! ! !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>The case for spam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>Re: The case for spam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>Re: The case for spam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>3</td>\n",
       "      <td>*****SPAM*****</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8485</th>\n",
       "      <td>3</td>\n",
       "      <td>This is the final test of a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8606</th>\n",
       "      <td>3</td>\n",
       "      <td>New... Find out ANYTHING about ANYONE from you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>package my stuff please :P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>4</td>\n",
       "      <td>package my stuff please :P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>4</td>\n",
       "      <td>xine src package</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4361</th>\n",
       "      <td>4</td>\n",
       "      <td>[Spambayes] Current histograms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>4</td>\n",
       "      <td>[Spambayes] Current histograms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>4</td>\n",
       "      <td>Find all files that aren't in package.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>5</td>\n",
       "      <td>[zzzzteana] Animal attraction for sale</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>5</td>\n",
       "      <td>[zzzzteana] Re: More Japanese stuff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>5</td>\n",
       "      <td>[zzzzteana] Fwd: Explorator 5.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster                                            subject  spam\n",
       "65          0                [use Perl] Headlines for 2002-08-30     0\n",
       "69          0                                NTK Now, 2002-08-30     0\n",
       "140         0                [use Perl] Headlines for 2002-10-08     0\n",
       "6432        0                  [use Perl] Stories for 2002-08-20     0\n",
       "6661        0                  [use Perl] Stories for 2002-08-18     0\n",
       "6878        0                  [use Perl] Stories for 2002-08-18     0\n",
       "329         1  Re: \"Ouch. Ouch. Ouch. Ouch. Ouch....\"(was Re:...     0\n",
       "340         1  Re: \"Ouch. Ouch. Ouch. Ouch. Ouch....\"(was Re:...     0\n",
       "467         1                                            Ouch...     0\n",
       "5915        1                                 Re: My brain hurts     0\n",
       "6062        1                       Re[3]: Forged whitelist spam     0\n",
       "6069        1                   Re: Re[3]: Forged whitelist spam     0\n",
       "54          2                   Re: [SAtalk] O.T. Habeus -- Why?     0\n",
       "186         2  [zzzzteana] \"Put this in your stereo and smoke...     0\n",
       "801         2                   Re: [SAtalk] O.T. Habeus -- Why?     0\n",
       "9293        2                       -- USA Business Search CD --     1\n",
       "9302        2                           ** You're -Approved-! **     1\n",
       "9334        2                   yyyy Your computer can READ! ! !     1\n",
       "15          3                                  The case for spam     0\n",
       "44          3                              Re: The case for spam     0\n",
       "76          3                              Re: The case for spam     0\n",
       "7596        3                                     *****SPAM*****     1\n",
       "8485        3                        This is the final test of a     1\n",
       "8606        3  New... Find out ANYTHING about ANYONE from you...     1\n",
       "87          4                         package my stuff please :P     0\n",
       "1219        4                         package my stuff please :P     0\n",
       "1387        4                                   xine src package     0\n",
       "4361        4                     [Spambayes] Current histograms     0\n",
       "4362        4                    [Spambayes] Current histograms      0\n",
       "6255        4             Find all files that aren't in package.     0\n",
       "1           5                          [zzzzteana] RE: Alexander     0\n",
       "2           5                          [zzzzteana] Moscow bomber     0\n",
       "4           5     Re: [zzzzteana] Nothing like mama used to make     0\n",
       "6447        5             [zzzzteana] Animal attraction for sale     0\n",
       "6448        5                [zzzzteana] Re: More Japanese stuff     0\n",
       "6643        5                   [zzzzteana] Fwd: Explorator 5.15     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most clusters with the lowest spread (stdev) in cluster counts\n",
    "dbscan.min_samples = 125\n",
    "dbscan.eps = 0.70\n",
    "\n",
    "clusters = dbscan.fit_predict(features_subject)\n",
    "clusters = pd.Series(clusters)\n",
    "clusters.index = df.index\n",
    "subject_clusters = pd.concat([ clusters, df['subject'], df['spam'] ], axis=1)\n",
    "subject_clusters.columns = ['cluster','subject', 'spam']\n",
    "\n",
    "heads_tails = pd.DataFrame({'cluster' : [], 'subject' : [], 'spam' : []}) \n",
    "for i in range( 0, max(clusters.unique())+1 ): # Exclude the -1 class which is a non-cluster\n",
    "    heads_tails = pd.concat([heads_tails, \n",
    "                             subject_clusters.loc[subject_clusters['cluster']==i].head(3),\n",
    "                             subject_clusters.loc[subject_clusters['cluster']==i].tail(3) ], axis=0)\n",
    "heads_tails[['cluster', 'spam']] = heads_tails[['cluster','spam']].astype(int)\n",
    "print('Head & tail of each cluster:')    \n",
    "heads_tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 111 spam cases, most in Cluster 2.  Clusters 0,1,4, and 5 have no spam and can be used for filtering or pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    956\n",
       "1    111\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_clusters.loc[subject_clusters['cluster']!=-1,'spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    127\n",
       "1    108\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_clusters.loc[subject_clusters['cluster']==2,'spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    252\n",
       "1      3\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_clusters.loc[subject_clusters['cluster']==3,'spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6qUPkzRN5D4"
   },
   "source": [
    "## Assumptions <a id='assumptions'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaEb4apWN5D4"
   },
   "source": [
    "Team made the assumption that emails are representative of future emails.  Team also made the assumption that the emails were properly categorized into folders as ham or spam.  For the spam detection to be effective, the model will need to be run and/or updated on a regular basis to ensure new trends in spam are captured.\n",
    "\n",
    "Naive Bayes is built with the assumption that all prediction variables(features) are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmuI_mep8g_b"
   },
   "source": [
    "# Model Preparations <a id='model-preparations'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classification problem, team found NLP useful for modeling because it is used for natural language processing.  (A natural language is one that develops naturally such as English, ASL, or Spanish.  An example of an artificial language is Klingon.)  Naïve Bayes was useful for classification because it looks at each classification individually.  It is the most popular method for spam detection because it gives a low result of false positive.  The dataset started with 6,086 features.  NLP only needed a fraction of the features in order to detect whether a message was spam or ham.  DBSCAN was useful for finding connections in the  data such as related words and noise.\n",
    "\n",
    "#### NLP and Naïve Bayes\n",
    "Data was processed using TFIDF (Term Frequency Inverse Data Frequency) to quantify and determine the rare words across the spam and ham emails in the training set for email body and subject. Gaussian Naive Bayes (GaussianNB) was used to build the model. Predicted outcomes of the train and test data set were compared with the actual outcome.\n",
    "\n",
    "The team decided to use NLP (Natural Language Processing) to read and identify the text in the email subject and body. Team performed cleanup efforts on unstructured text data and removed unwanted characters and symbols to create a structured alphanumeric data frame. \n",
    "\n",
    "The Naïve Bayes algorithm was used to classify the data. This classification technique works well when features predicting the target classification are independent of each other, and it is a proven method for effectively classifying spam.  \n",
    "\n",
    "#### DBSCAN\n",
    "Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm is used to find associations and structures in data that are challenging to find manually but are relevant and valuable to find patterns and predict trends. DBSCAN groups the data points close to each other based on the density and distance measured. It also identifies the outliers in low-density regions. In the case of email, it will be able to identify closely related words and separate the noise or irreverent words. This algorithm effectively manages outliers by detecting them and considering them as a separate (not able to cluster them) cluster(s). DBSCAN allows for easy execution of distance measures. Cosine distance measures the distance between vectors by calculating cosine angle vectors, i.e., two overlapping vectors will have minimum values. Cosine distance works excellent with text. \n",
    "\n",
    "#### Metrics\n",
    "The metrics used to evaluate model performance were accuracy, time to process, and F1. Time to process the emails was also considered to be an essential factor. So, the team had to find the right balance between the three legs of stool (accuracy, time to process, and F1).\n",
    "\n",
    "Accuracy refers to the level of agreement between the actual measurement and the predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuRjMsjg8g_d"
   },
   "source": [
    "# Model Building & Evaluations <a id='model-building'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering with DBSCAN approach is discussed in the EDA section above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was split into training and test sets with a 70/30 ratio, respectively. Care was taken to manage the imbalance of spam and ham in the training and test sets. Specifically, StratifiedShuffleSplit was used to ensure class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dependant_and_independant_variables(df: pd.DataFrame, y_var: str):\n",
    "    X = df.copy()\n",
    "    y = X[y_var]\n",
    "    X = X.drop([y_var], axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split(X, y, test_size, random_state):\n",
    "    stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    for train_index, test_index in stratified_shuffle_split.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_dependant_and_independant_variables(df, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = shuffle_split(X, y, test_size=0.3, random_state=12343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subject_train = vectorizer.fit_transform(X_train['clean_subject'])\n",
    "features_subject_test = vectorizer.transform(X_test['clean_subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_body_train = vectorizer.fit_transform(X_train['clean_body'])\n",
    "features_body_test = vectorizer.transform(X_test['clean_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "features_joined_train = sparse.hstack((features_subject_train, features_body_train), format='csr') \n",
    "features_joined_test = sparse.hstack((features_subject_test, features_body_test), format='csr') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Using all the extracted features resulting in overfitting the training set, longer processing time and degredation in F1 value.  To mitigate these issues, the team reduced the number of features in the model utilzing Select Percentile from Sklearn feature selection. Multiple iterations were done to reduce the features from 100% to 50% to 1% or less.  The team found only 1% of the features was best for predicting spam without overfitting.  This reduction of features drastically improved the processing time (~80 times as fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 5\n",
    "selector = SelectPercentile(f_classif, percentile=percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(features_subject_train, y_train)\n",
    "features_subject_train_sel = selector.transform(features_subject_train).toarray()\n",
    "features_subject_test_sel = selector.transform(features_subject_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(features_body_train, y_train)\n",
    "features_body_train_sel = selector.transform(features_body_train).toarray()\n",
    "features_body_test_sel = selector.transform(features_body_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(features_joined_train, y_train)\n",
    "features_joined_train_sel = selector.transform(features_joined_train).toarray()\n",
    "features_joined_test_sel = selector.transform(features_joined_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance is discussed in the conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy\n",
    "If the model simply predicted everything as ham, it would be 74% accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.743505\n",
       "1    0.256495\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline accuracy of 74% with class imbalance\n",
    "df['spam'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_feature_importance(model, vectorizer, indicator):\n",
    "    return sorted(list(zip(vectorizer.get_feature_names(), model.feature_log_prob_[indicator])), key=lambda t: t[1], reverse=True)\n",
    "\n",
    "def measure_time(func, name, percentile, features, vectorizer):\n",
    "    start = time.process_time()\n",
    "    train_pred, test_pred, model = func()\n",
    "    processing_time = time.process_time() - start\n",
    "    return [name, percentile, features, round(accuracy_score(y_train, train_pred),2), round(accuracy_score(y_test, test_pred), 2), round(f1_score(y_test, test_pred),2), round(processing_time, 4)], score_feature_importance(model, vectorizer, 0)[:100], score_feature_importance(model, vectorizer, 1)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes\n",
    "The Naïve Bayes algorithm was used to classify the data. This classification technique works well when features predicting the target classification are independent of each other, and it is a proven method for effectively classifying spam.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with All Body Features - Baseline Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_body_train_all = features_body_train.toarray()\n",
    "features_body_test_all = features_body_test.toarray()\n",
    "def run_model0(): \n",
    "    model0 = MultinomialNB()\n",
    "    model0.fit(features_body_train_all, y_train)\n",
    "    train_pred = model0.predict(features_body_train_all)\n",
    "    test_pred = model0.predict(features_body_test_all)\n",
    "    return train_pred, test_pred, model0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with All Subject Features - Baseline Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subject_train_all = features_subject_train.toarray()\n",
    "features_subject_test_all = features_subject_test.toarray()\n",
    "def run_model1(): \n",
    "    model1a = MultinomialNB()\n",
    "    model1a.fit(features_subject_train_all, y_train)\n",
    "    train_pred = model1a.predict(features_subject_train_all)\n",
    "    test_pred = model1a.predict(features_subject_test_all)\n",
    "    return train_pred, test_pred, model1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with 5% of Subject Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_model2():\n",
    "    model1b = MultinomialNB()\n",
    "    model1b.fit(features_subject_train_sel, y_train)\n",
    "    train_pred = model1b.predict(features_subject_train_sel)\n",
    "    test_pred = model1b.predict(features_subject_test_sel)\n",
    "    return train_pred, test_pred, model1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with 5% of Body Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model3():\n",
    "    model2 = MultinomialNB()\n",
    "    model2.fit(features_body_train_sel, y_train)\n",
    "    train_pred = model2.predict(features_body_train_sel)\n",
    "    test_pred = model2.predict(features_body_test_sel)\n",
    "    return train_pred, test_pred, model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with 1% of Body Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(f_classif, percentile=1)\n",
    "selector.fit(features_body_train, y_train)\n",
    "features_body_train_sel_point1 = selector.transform(features_body_train).toarray()\n",
    "features_body_test_sel_point1 = selector.transform(features_body_test).toarray()\n",
    "def run_model4():\n",
    "    model2b = MultinomialNB()\n",
    "    model2b.fit(features_body_train_sel_point1, y_train)\n",
    "    train_pred = model2b.predict(features_body_train_sel_point1)\n",
    "    test_pred = model2b.predict(features_body_test_sel_point1)\n",
    "    return train_pred, test_pred, model2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with 5% of Subject + Body Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model5():\n",
    "    model3 = MultinomialNB()\n",
    "    model3.fit(features_joined_train_sel, y_train)\n",
    "    train_pred = model3.predict(features_joined_train_sel)\n",
    "    test_pred = model3.predict(features_joined_test_sel)\n",
    "    return train_pred, test_pred, model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with 1% of Subject + Body Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(f_classif, percentile=1)\n",
    "selector.fit(features_joined_train, y_train)\n",
    "features_joined_train_sel_point_1 = selector.transform(features_joined_train).toarray()\n",
    "features_joined_test_sel_point_1 = selector.transform(features_joined_test).toarray()\n",
    "def run_model6():\n",
    "    model2b = MultinomialNB()\n",
    "    model2b.fit(features_joined_train_sel_point_1, y_train)\n",
    "    train_pred = model2b.predict(features_joined_train_sel_point_1)\n",
    "    test_pred = model2b.predict(features_joined_test_sel_point_1)\n",
    "    return train_pred, test_pred, model2b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result0, neg_priority0, pos_priority0 = measure_time(run_model0, 'body',100, features_body_train_all.shape[1], vectorizer)\n",
    "result1, neg_priority1, pos_priority1 = measure_time(run_model1, 'subject', 100, features_subject_train_all.shape[1], vectorizer)\n",
    "result2, neg_priority2, pos_priority2 = measure_time(run_model2, 'subject', percentile, features_subject_train_sel.shape[1], vectorizer)\n",
    "result3, neg_priority3, pos_priority3 = measure_time(run_model3, 'body', percentile, features_body_train_sel.shape[1], vectorizer)\n",
    "result4, neg_priority4, pos_priority4 = measure_time(run_model4, 'body', 1, features_body_train_sel_point1.shape[1], vectorizer)\n",
    "result5, neg_priority5, pos_priority5 = measure_time(run_model5, 'subject+body', percentile, features_joined_train_sel.shape[1], vectorizer)\n",
    "result6, neg_priority6, pos_priority6 = measure_time(run_model6, 'subject+body', 1, features_joined_test_sel_point_1.shape[1], vectorizer)\n",
    "\n",
    "result = [result0, result1, result2, result3, result4, result5, result6 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type            Percentile    # of Features    Train Accuracy    Test Accuracy    f1-score    Processing Time\n",
      "------------  ------------  ---------------  ----------------  ---------------  ----------  -----------------\n",
      "body                   100            84542              0.94             0.92        0.82            32.1562\n",
      "subject                100             5891              0.96             0.92        0.81             2.5938\n",
      "subject                  5              295              0.87             0.85        0.6              0.0938\n",
      "body                     5             4227              0.97             0.96        0.92             1.8594\n",
      "body                     1              846              0.94             0.93        0.85             0.2812\n",
      "subject+body             5             4521              0.97             0.97        0.93             2.1562\n",
      "subject+body             1              905              0.95             0.94        0.87             0.2969\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(result, headers=['Type', 'Percentile', '# of Features', 'Train Accuracy', 'Test Accuracy', 'f1-score', 'Processing Time' ]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbAhMB1x8g_e"
   },
   "source": [
    "# Conclusion <a id='conclusion'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classification problem, team found NLP useful for modeling because it is used for natural language processing. (A natural language is one that develops naturally such as English, ASL, or Spanish. An example of an artificial language is Klingon.) \n",
    "\n",
    "Naïve Bayes was useful for classification because treats each feature as independent. It is the most popular method for spam detection because it gives a low result of false positive. The dataset started with 6,086 features. NLP only needed a fraction of the features in order to detect whether a message was spam or ham. DBSCAN was useful for finding connections in the data such as related words and noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnsadV7M8g_e"
   },
   "source": [
    "### Final Model Proposal <a id='final-model-proposal'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team's objective was to maximize accuracy while minimizing the number of features and processing time, to make predictions in real time.  The best model used 1% of the features from the email subject+body with 832 features, F1-score of 0.88, and processing time of 0.103 seconds (so fast!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XXMCBozN5D-"
   },
   "source": [
    "| Type         | Percentile | No of Features | Train Accuracy | Test Accuracy | f1-score | Processing Time |\n",
    "|--------------|------------|----------------|----------------|---------------|----------|-----------------|\n",
    "| body         | 100        | 77396          | 0.95           | 0.93          | 0.83     | 7.9631          |\n",
    "| subject      | 100        | 6086           | 0.96           | 0.92          | 0.81     | 0.8683          |\n",
    "| subject      | 1          | 59             | 0.8            | 0.8           | 0.37     | 0.0195          |\n",
    "| body         | 1          | 773            | 0.94           | 0.93          | 0.85     | 0.0861          |\n",
    "| body         | 0.1        | 78             | 0.83           | 0.83          | 0.52     | 0.0175          |\n",
    "| __subject+body__ | __1__          | __832__            | __0.94__           | __0.94__          | __0.88__     | __0.103__           |\n",
    "| subject+body | 0.1        | 84             | 0.84           | 0.84          | 0.55     | 0.0138          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX8fXYczN5D-"
   },
   "source": [
    "### Future Considerations and Model Enhancements <a id='model-enhancements'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzeTkIEWN5D-"
   },
   "source": [
    "In order for the spam detection to be effective, the model will need to be run and/or updated on a regular basis to ensure new trends in spam are captured.  \n",
    "\n",
    "The team will recommend future evaluation of leveraging output of DBSCAN to feed the Naïve Bayes algorithm to optimize the outcome further. This algorithm has to be updated regularly to keep it updated to manage new spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References <a id='references'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1].  What is Spam? | Webopedia\n",
    "\n",
    "[2] Spam Statistics and Facts (spamlaws.com)\n",
    "\n",
    "[3] Team drew inspriation from https://towardsdatascience.com/training-a-naive-bayes-model-to-identify-the-author-of-an-email-or-document-17dc85fa630a"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Case_Study_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
