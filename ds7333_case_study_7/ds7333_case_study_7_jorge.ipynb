{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import re\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "#import sklearn\n",
    "#import time\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "import xgboost\n",
    "\n",
    "# data pre-processing\n",
    "from scipy.io import arff\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.impute._base import _BaseImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection._split import BaseShuffleSplit\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# prediction models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm._base import BaseSVC \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "\n",
    "# import warnings filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilePathManager:\n",
    "    def __init__(self, local_dir: str):\n",
    "        self.local_dir = local_dir\n",
    "    \n",
    "    def retrieve_full_path(self):\n",
    "        return os.getcwd()+'/'+self.local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def load_data(self, file_name):\n",
    "        pass\n",
    "    \n",
    "    def get_df(self):\n",
    "        pass\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    " \n",
    "class CSVLoader(Loader):\n",
    "    def __init__(self, file_path_manager: FilePathManager):\n",
    "        self.file_path_manager = file_path_manager\n",
    "        \n",
    "    def load_data(self, _prepare_data: Callable[[pd.DataFrame], pd.DataFrame] = None):\n",
    "        self.df = pd.read_csv(self.file_path_manager.retrieve_full_path())\n",
    "        if _prepare_data:\n",
    "            self.df = _prepare_data(self.df)\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df;\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df['y'] = df['y'].astype(int)\n",
    "    df['x32'] = df['x32'].str.replace('%','').astype(float)\n",
    "    df['x37'] = df['x37'].str.replace('$','').astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x32</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x37</th>\n",
       "      <th>x24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>July</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>$1313.96</td>\n",
       "      <td>euorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.02%</td>\n",
       "      <td>Aug</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$1962.78</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$430.47</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$-2366.29</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>$-620.66</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>Aug</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$-891.96</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>-0.01%</td>\n",
       "      <td>May</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$1588.65</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>-0.0%</td>\n",
       "      <td>Jun</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$687.46</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>-0.02%</td>\n",
       "      <td>May</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$439.21</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>0.02%</td>\n",
       "      <td>Aug</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>$-1229.34</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x32   x29        x30        x37     x24\n",
       "0         0.0%  July    tuesday   $1313.96  euorpe\n",
       "1       -0.02%   Aug  wednesday   $1962.78    asia\n",
       "2       -0.01%  July  wednesday    $430.47    asia\n",
       "3        0.01%  July  wednesday  $-2366.29    asia\n",
       "4        0.01%  July    tuesday   $-620.66    asia\n",
       "...        ...   ...        ...        ...     ...\n",
       "159995    0.0%   Aug  wednesday   $-891.96    asia\n",
       "159996  -0.01%   May  wednesday   $1588.65    asia\n",
       "159997   -0.0%   Jun  wednesday    $687.46    asia\n",
       "159998  -0.02%   May  wednesday    $439.21    asia\n",
       "159999   0.02%   Aug    tuesday  $-1229.34    asia\n",
       "\n",
       "[160000 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cat_vars=[*cat_vars]\n",
    "df[my_cat_vars].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "159995    1\n",
       "159996    1\n",
       "159997    1\n",
       "159998    1\n",
       "159999    1\n",
       "Name: x24, Length: 160000, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x32</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x37</th>\n",
       "      <th>x24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>July</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>$1313.96</td>\n",
       "      <td>euorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.02%</td>\n",
       "      <td>Aug</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$1962.78</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$430.47</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$-2366.29</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>$-620.66</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>Aug</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$-891.96</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>-0.01%</td>\n",
       "      <td>May</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$1588.65</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>-0.0%</td>\n",
       "      <td>Jun</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$687.46</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>-0.02%</td>\n",
       "      <td>May</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>$439.21</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>0.02%</td>\n",
       "      <td>Aug</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>$-1229.34</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x32   x29        x30        x37     x24\n",
       "0         0.0%  July    tuesday   $1313.96  euorpe\n",
       "1       -0.02%   Aug  wednesday   $1962.78    asia\n",
       "2       -0.01%  July  wednesday    $430.47    asia\n",
       "3        0.01%  July  wednesday  $-2366.29    asia\n",
       "4        0.01%  July    tuesday   $-620.66    asia\n",
       "...        ...   ...        ...        ...     ...\n",
       "159995    0.0%   Aug  wednesday   $-891.96    asia\n",
       "159996  -0.01%   May  wednesday   $1588.65    asia\n",
       "159997   -0.0%   Jun  wednesday    $687.46    asia\n",
       "159998  -0.02%   May  wednesday    $439.21    asia\n",
       "159999   0.02%   Aug    tuesday  $-1229.34    asia\n",
       "\n",
       "[160000 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['x32', 'x29', 'x30', 'x37', 'x24']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(FilePathManager('final_project(5).csv'))\n",
    "loader.load_data(clean_data)\n",
    "df = loader.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseImputer:\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        pass\n",
    "\n",
    "class BaseModel:\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling:\n",
    "    _X_train_fitted = None\n",
    "    _X_test_fitted = None\n",
    "    _y_train = None\n",
    "    _y_test = None\n",
    "    _y_preds = None\n",
    "    _y_preds_proba = None\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                 target_name: str, \n",
    "                 shuffle_splitter: BaseShuffleSplit, \n",
    "                 imputer: BaseImputer, \n",
    "                 model: BaseModel, scaler = None, encoder = None):\n",
    "        self._data = data\n",
    "        self._target_name = target_name\n",
    "        self._shuffle_splitter = shuffle_splitter\n",
    "        self._imputer = imputer\n",
    "        self._model = model\n",
    "        self._encoder = encoder\n",
    "        self._X, self._y = self._split_data()\n",
    "        self._scaler = scaler\n",
    "        \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self._model = model\n",
    "     \n",
    "    @property\n",
    "    def X_train(self):\n",
    "        return self._X_train_fitted\n",
    "    \n",
    "    @property\n",
    "    def X_test(self):\n",
    "        return self._X_test_fitted\n",
    "    \n",
    "    @property\n",
    "    def y_train(self):\n",
    "        return self._y_train\n",
    "    \n",
    "    @property\n",
    "    def y_test(self):\n",
    "        return self._y_test\n",
    "    \n",
    "    @property\n",
    "    def y_preds(self):\n",
    "        return self._y_preds\n",
    "    \n",
    "    def _split_data(self):\n",
    "        X = self._data.copy()\n",
    "        return X.drop([self._target_name], axis=1) , X[self._target_name]\n",
    "    \n",
    "    def _shuffle_split(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        for train_index, test_index in self._shuffle_splitter.split(X,y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def _fit_imputer(self, train):\n",
    "        if self._imputer is not None:\n",
    "            self._imputer.fit(train)\n",
    "    \n",
    "    def _fit_scaler(self, train, cont_vars = None):\n",
    "        transform_cols = None\n",
    "        if cont_vars is None:\n",
    "            transform_cols = self.X.columns\n",
    "        else:\n",
    "            transform_cols = cont_vars\n",
    "            \n",
    "        if self._scaler is not None:\n",
    "            self._scaler.fit(train[transform_cols])\n",
    "    \n",
    "    def _impute_data(self, X: pd.DataFrame):\n",
    "        if self._imputer is not None:\n",
    "            return pd.DataFrame(self._imputer.transform(X), columns = self.X.columns, index = X.index)\n",
    "        return X\n",
    "    \n",
    "    def _scale_data(self, X: pd.DataFrame, cont_vars = None):\n",
    "        transform_cols = None\n",
    "        if cont_vars is None:\n",
    "            transform_cols = X.columns\n",
    "        else:\n",
    "            transform_cols = cont_vars\n",
    "        scaled_data = X[transform_cols]\n",
    "        if self._scaler is not None:\n",
    "            scaled_data = pd.DataFrame(self._scaler.transform(X[transform_cols]), columns = transform_cols)\n",
    "        X[transform_cols] = scaled_data\n",
    "        return X\n",
    "    \n",
    "    def _encode_data(self):\n",
    "        df = self.X.copy()\n",
    "        cont_vars = df.describe().columns\n",
    "        cat_vars = set(df.columns) - set(cont_vars)\n",
    "        for column in [*cat_vars]:\n",
    "            df[column] = self._encoder.fit_transform(df[column].astype(str))\n",
    "        self._X = df\n",
    "        return cont_vars, cat_vars\n",
    "        \n",
    "    \n",
    "    def prepare(self):\n",
    "        cont_vars = None\n",
    "        if self._encoder is not None: \n",
    "            cont_vars, _ = self._encode_data()\n",
    "        X_train, X_test, y_train, y_test = self._shuffle_split()   \n",
    "        self._fit_imputer(X_train)\n",
    "        X_train = self._impute_data(X_train)\n",
    "        X_test = self._impute_data(X_test)\n",
    "        self._fit_scaler(X_train, cont_vars)\n",
    "        self._X_train_fitted = self._scale_data(X_train, cont_vars)\n",
    "        self._X_test_fitted = self._scale_data(X_test, cont_vars)\n",
    "        self._y_train = y_train\n",
    "        self._y_test = y_test\n",
    "        \n",
    "    def prepare_and_train(self):\n",
    "        self.prepare()\n",
    "        return self.train()\n",
    "        \n",
    "    def train(self):\n",
    "        self._model.fit(self.X_train, self.y_train)\n",
    "        self._y_preds = self._model.predict(self.X_train)\n",
    "        self._y_preds_proba = self._model.predict_proba(self.X_train)\n",
    "        \n",
    "        return self.metrics(self.y_train, self.y_preds, self._y_preds_proba)\n",
    "        \n",
    "    def test(self):\n",
    "        return self.metrics(self.y_test, self._model.predict(self.X_test), self._model.predict_proba(self.X_test))\n",
    "       \n",
    "    @abstractmethod\n",
    "    def metrics(self, y_true = None, y_pred = None, y_preds_proba = None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "       'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "       'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40',\n",
       "       'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBModel:\n",
    "    _model = None\n",
    "    \n",
    "    def __init__(self, params, num_round: int = 100):\n",
    "        self._params = params\n",
    "        self._num_round = num_round\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        dtrain = xgb.DMatrix(X, label = y)\n",
    "        self._model = xgb.train(self._params, dtrain)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self._model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModeling(Modeling):\n",
    "    def __init__(self, \n",
    "                 data: pd.DataFrame, \n",
    "                 target_name: str, \n",
    "                 shuffle_splitter: BaseShuffleSplit, \n",
    "                 imputer: BaseImputer, \n",
    "                 model: BaseModel, \n",
    "                 scaler = None,\n",
    "                 encoder = None,\n",
    "                 beta: int = 1, \n",
    "                 classification: str = 'binary'):\n",
    "        super().__init__(data, target_name, shuffle_splitter, imputer, model, scaler, encoder)\n",
    "        self.beta = beta\n",
    "        self.classification = classification\n",
    "        \n",
    "    @abstractmethod\n",
    "    def metrics(self, y_true = None, y_pred = None, y_preds_proba=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, TypeVar\n",
    "\n",
    "class XGBClassificationModeling(ClassificationModeling):\n",
    "    TXGB = TypeVar(\"TXGB\", bound=XGBClassifier)\n",
    "    all_models = [];\n",
    "    \n",
    "    def __init__(self, \n",
    "             data: pd.DataFrame, \n",
    "             target_name: str, \n",
    "             shuffle_splitter: BaseShuffleSplit, \n",
    "             imputer: BaseImputer, \n",
    "             model: BaseModel, \n",
    "             scaler = None,\n",
    "             encoder = None,\n",
    "             beta: int = 1, \n",
    "             classification: str = 'binary'):\n",
    "         super().__init__(data, target_name, shuffle_splitter, imputer, model, scaler, encoder, beta, classification)\n",
    "        \n",
    "            \n",
    "    def parameter_tuning(self, params, class_to_instantiate: Type[TXGB]):\n",
    "        list_of_models = []\n",
    "        combination = []\n",
    "        params_base = {}\n",
    "        output = []\n",
    "        for key, value in params.items():\n",
    "            if isinstance(value, list):\n",
    "                combination.append((key,value))\n",
    "            else:\n",
    "                params_base[key]=value\n",
    "              \n",
    "        result = XGBClassificationModeling.get_combinations(combination)\n",
    "\n",
    "        for r in result:\n",
    "            list_of_models.append(class_to_instantiate(**{**params_base, **r}))\n",
    "            \n",
    "        for a_model in list_of_models:\n",
    "            self.model = a_model\n",
    "            startTrain = time.time()\n",
    "            train_metrics = self.train()\n",
    "            endTrain = time.time()\n",
    "            test_metrics = self.test()\n",
    "            endTest = time.time()\n",
    "            train_time = endTrain - startTrain\n",
    "            test_time = endTest - endTrain\n",
    "            output.append({'model': a_model, 'train_metrics': {**train_metrics,**{'elapsed_time':train_time}}, 'test_metrics': {**test_metrics,**{'elapsed_time':test_time}}})\n",
    "        self.all_models = output\n",
    "        return output\n",
    "        \n",
    "    def find_best_model(self):\n",
    "        max_accuracy = self.all_models[0]['test_metrics']['accuracy']\n",
    "        location = 0\n",
    "        for indx, output_metrics in enumerate(self.all_models):\n",
    "            if max_accuracy < output_metrics['test_metrics']['accuracy']:\n",
    "                max_accuracy = output_metrics['test_metrics']['accuracy']\n",
    "                location = indx\n",
    "            elif max_accuracy == output_metrics['test_metrics']['accuracy']:\n",
    "                if output_metrics['test_metrics']['elapsed_time'] < self.all_models[location]['test_metrics']['elapsed_time']:\n",
    "                    location = indx\n",
    "                \n",
    "        return self.all_models[location]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_combinations(tuples):\n",
    "        length = len(tuples)\n",
    "        if length > 1:\n",
    "            total_params = []\n",
    "            tuple_copy = tuples.copy()\n",
    "            a_tuple = tuple_copy.pop(0)\n",
    "            params_list = XGBClassificationModeling.get_combinations(tuple_copy)\n",
    "            for value in a_tuple[1]:\n",
    "                for a_params in params_list:\n",
    "                    temp = { a_tuple[0]: value}\n",
    "                    total_params.append({**temp, **a_params})\n",
    "            return total_params\n",
    "        else:\n",
    "            params_list = []\n",
    "            a_tuple =  tuples[0]\n",
    "            for value in a_tuple[1]:\n",
    "                temp = {}\n",
    "                temp[a_tuple[0]] = value\n",
    "                params_list.append(temp)\n",
    "            return params_list\n",
    "            \n",
    "    \n",
    "    def metrics(self, y_true = None, y_pred = None, y_pred_proba = None):\n",
    "        if y_true is None and y_pred is None:\n",
    "            y_true = self.y_train\n",
    "            y_pred = self.y_preds       \n",
    "        return {\n",
    "                'matrix': confusion_matrix(y_true, y_pred), \n",
    "                'accuracy': round(accuracy_score(y_true, y_pred), 5), \n",
    "                'precision': precision_score(y_true, y_pred, average=self.classification), \n",
    "                'recall': recall_score(y_true, y_pred, average=self.classification),\n",
    "                'f1': f1_score(y_true, y_pred),\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassificationModeling(loader.get_df(),'y',\n",
    "                                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                           None, XGBClassifier, None, LabelEncoder(), beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "159995    1\n",
       "159996    1\n",
       "159997    1\n",
       "159998    1\n",
       "159999    1\n",
       "Name: x24, Length: 160000, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.X['x24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_results = xgb_classifier.parameter_tuning( { \n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [100],\n",
    "    'colsample_bytree': [0.3],\n",
    " }, XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=0.3,\n",
       "                enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "                importance_type=None, interaction_constraints='',\n",
       "                learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                subsample=1, tree_method='exact', validate_parameters=1,\n",
       "                verbosity=None),\n",
       "  'train_metrics': {'matrix': array([[60663,  6399],\n",
       "          [12781, 32157]]),\n",
       "   'accuracy': 0.82875,\n",
       "   'precision': 0.8340336134453782,\n",
       "   'recall': 0.7155859183764297,\n",
       "   'f1': 0.7702828945792514,\n",
       "   'elapsed_time': 24.367619037628174},\n",
       "  'test_metrics': {'matrix': array([[25890,  2851],\n",
       "          [ 5630, 13629]]),\n",
       "   'accuracy': 0.82331,\n",
       "   'precision': 0.827002427184466,\n",
       "   'recall': 0.7076691416999844,\n",
       "   'f1': 0.76269621421976,\n",
       "   'elapsed_time': 0.2505919933319092}}]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:52:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:55:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:57:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:04:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:05:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:08:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:21:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:23:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:26:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:58:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:59:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:00:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:09:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:14:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:13:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:14:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:54:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:58:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:26:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_results = xgb_classifier.parameter_tuning( { \n",
    "    'max_depth': [3,6,10],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    " }, XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.7,\n",
       "               enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=1000, n_jobs=8, num_parallel_tree=1,\n",
       "               predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "               scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "               validate_parameters=1, verbosity=None),\n",
       " 'train_metrics': {'matrix': array([[67062,     0],\n",
       "         [    0, 44938]]),\n",
       "  'accuracy': 1.0,\n",
       "  'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1': 1.0,\n",
       "  'elapsed_time': 101146.86843967438},\n",
       " 'test_metrics': {'matrix': array([[27657,  1084],\n",
       "         [ 1452, 17807]]),\n",
       "  'accuracy': 0.94717,\n",
       "  'precision': 0.9426181779683447,\n",
       "  'recall': 0.9246066773975804,\n",
       "  'f1': 0.9335255570117955,\n",
       "  'elapsed_time': 0.7830641269683838}}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.find_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, TypeVar\n",
    "\n",
    "class TuningClassificationModeling(ClassificationModeling):\n",
    "    TClass = None\n",
    "    all_models = [];\n",
    "    \n",
    "    def __init__(self, \n",
    "             data: pd.DataFrame, \n",
    "             target_name: str, \n",
    "             shuffle_splitter: BaseShuffleSplit, \n",
    "             imputer: BaseImputer, \n",
    "             model: BaseModel, \n",
    "             scaler = None,\n",
    "             encoder = None,\n",
    "             beta: int = 1, \n",
    "             classification: str = 'binary',\n",
    "                 classification_type: str = 'logistic'):\n",
    "        super().__init__(data, target_name, shuffle_splitter, imputer, model, scaler, encoder, beta, classification)\n",
    "        if classification_type == 'logistic':\n",
    "            TClass = TypeVar(\"TClass\", bound=LogisticRegression)\n",
    "        elif classification_type == 'xgb':\n",
    "            TClass = TypeVar(\"TClass\", bound=XGBClassifier)\n",
    "        elif classification_type == 'neural':\n",
    "            TClass = TypeVar(\"TClass\", bound=NNModel)\n",
    "            \n",
    "\n",
    "    def parameter_tuning(self, params, class_to_instantiate: Type[TClass]):\n",
    "        list_of_models = []\n",
    "        combination = []\n",
    "        params_base = {}\n",
    "        output = []\n",
    "        for key, value in params.items():\n",
    "            if isinstance(value, list):\n",
    "                combination.append((key,value))\n",
    "            else:\n",
    "                params_base[key]=value\n",
    "        result = {}\n",
    "        if len(combination) > 0:       \n",
    "            result = TuningClassificationModeling.get_combinations(combination)\n",
    "        print(params_base)\n",
    "        for r in result:\n",
    "            list_of_models.append(class_to_instantiate(**{**params_base, **r}))\n",
    "            \n",
    "        for a_model in list_of_models:\n",
    "            self.model = a_model\n",
    "            startTrain = time.time()\n",
    "            train_metrics = self.train()\n",
    "            endTrain = time.time()\n",
    "            test_metrics = self.test()\n",
    "            endTest = time.time()\n",
    "            train_time = endTrain - startTrain\n",
    "            test_time = endTest - endTrain\n",
    "            output.append({'model': a_model, 'train_metrics': {**train_metrics,**{'elapsed_time':train_time}}, 'test_metrics': {**test_metrics,**{'elapsed_time':test_time}}})\n",
    "        self.all_models = output\n",
    "        return output\n",
    "        \n",
    "    def find_best_model(self, metric):\n",
    "        max_accuracy = self.all_models[0]['test_metrics'][metric]\n",
    "        location = 0\n",
    "        for indx, output_metrics in enumerate(self.all_models):\n",
    "            if max_accuracy < output_metrics['test_metrics'][metric]:\n",
    "                max_accuracy = output_metrics['test_metrics'][metric]\n",
    "                location = indx\n",
    "            elif max_accuracy == output_metrics['test_metrics'][metric]:\n",
    "                if output_metrics['test_metrics']['elapsed_time'] < self.all_models[location]['test_metrics']['elapsed_time']:\n",
    "                    location = indx\n",
    "                \n",
    "        return self.all_models[location]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_combinations(tuples):\n",
    "        length = len(tuples)\n",
    "        if length > 1:\n",
    "            total_params = []\n",
    "            tuple_copy = tuples.copy()\n",
    "            a_tuple = tuple_copy.pop(0)\n",
    "            params_list = TuningClassificationModeling.get_combinations(tuple_copy)\n",
    "            for value in a_tuple[1]:\n",
    "                for a_params in params_list:\n",
    "                    temp = { a_tuple[0]: value}\n",
    "                    total_params.append({**temp, **a_params})\n",
    "            return total_params\n",
    "        else:\n",
    "            params_list = []\n",
    "            a_tuple =  tuples[0]\n",
    "            for value in a_tuple[1]:\n",
    "                temp = {}\n",
    "                temp[a_tuple[0]] = value\n",
    "                params_list.append(temp)\n",
    "            return params_list\n",
    "            \n",
    "    \n",
    "    def metrics(self, y_true = None, y_pred = None, y_pred_proba=None):\n",
    "        if y_true is None and y_pred is None:\n",
    "            y_true = self.y_train\n",
    "            y_pred = self.y_preds\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return  {\n",
    "                'matrix': conf_matrix, \n",
    "                'auc': roc_auc_score(y_true, y_pred),\n",
    "                'accuracy': round(accuracy_score(y_true, y_pred), 5), \n",
    "                'precision': precision_score(y_true, y_pred, average=self.classification), \n",
    "                'recall': recall_score(y_true, y_pred, average=self.classification),\n",
    "                'f1': f1_score(y_true, y_pred),\n",
    "                'cost': TuningClassificationModeling.cost_calc(conf_matrix),\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba\n",
    "               }\n",
    "    \n",
    "    @staticmethod\n",
    "    def cost_calc(conf_matrix):\n",
    "        cost_matrix = np.array([[0,-100],[-25,0]])\n",
    "        cost = np.sum(cost_matrix*conf_matrix)/np.sum(conf_matrix)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_modeling = TuningClassificationModeling(loader.get_df(),'y',\n",
    "                                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                           SimpleImputer(missing_values=np.nan, strategy='mean'), LogisticRegression, None, LabelEncoder(), beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_modeling.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'random_state': 1, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "linear_result = linear_modeling.parameter_tuning( { \n",
    "    'penalty':'l2', #change to l1\n",
    "    'random_state':1,\n",
    "    'solver': 'liblinear',\n",
    "    'C':  [0.001, 0.01, 1, 10],\n",
    " }, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': LogisticRegression(C=0.001, random_state=1, solver='liblinear'),\n",
       "  'train_metrics': {'matrix': array([[55387, 11675],\n",
       "          [21518, 23420]]),\n",
       "   'auc': 0.673534929921288,\n",
       "   'accuracy': 0.70363,\n",
       "   'precision': 0.6673315287077931,\n",
       "   'recall': 0.5211624905425253,\n",
       "   'f1': 0.5852585808354054,\n",
       "   'cost': -15.227232142857142,\n",
       "   'y_pred': array([1, 1, 0, ..., 0, 0, 1]),\n",
       "   'y_pred_proba': array([[0.14075395, 0.85924605],\n",
       "          [0.33423334, 0.66576666],\n",
       "          [0.61417412, 0.38582588],\n",
       "          ...,\n",
       "          [0.8398927 , 0.1601073 ],\n",
       "          [0.65163991, 0.34836009],\n",
       "          [0.30405237, 0.69594763]]),\n",
       "   'elapsed_time': 6.521888971328735},\n",
       "  'test_metrics': {'matrix': array([[23648,  5093],\n",
       "          [ 9243, 10016]]),\n",
       "   'auc': 0.6714326204801649,\n",
       "   'accuracy': 0.70133,\n",
       "   'precision': 0.6629161426964061,\n",
       "   'recall': 0.5200685393841841,\n",
       "   'f1': 0.5828677839851025,\n",
       "   'cost': -15.424479166666666,\n",
       "   'y_pred': array([1, 0, 0, ..., 0, 1, 0]),\n",
       "   'y_pred_proba': array([[0.34566391, 0.65433609],\n",
       "          [0.56366816, 0.43633184],\n",
       "          [0.89095928, 0.10904072],\n",
       "          ...,\n",
       "          [0.7267635 , 0.2732365 ],\n",
       "          [0.08251836, 0.91748164],\n",
       "          [0.86682084, 0.13317916]]),\n",
       "   'elapsed_time': 0.1322469711303711}},\n",
       " {'model': LogisticRegression(C=0.01, random_state=1, solver='liblinear'),\n",
       "  'train_metrics': {'matrix': array([[55483, 11579],\n",
       "          [21607, 23331]]),\n",
       "   'auc': 0.6732604322529667,\n",
       "   'accuracy': 0.7037,\n",
       "   'precision': 0.6683185333715268,\n",
       "   'recall': 0.5191819840669367,\n",
       "   'f1': 0.584385332131049,\n",
       "   'cost': -15.161383928571428,\n",
       "   'y_pred': array([1, 1, 0, ..., 0, 0, 1]),\n",
       "   'y_pred_proba': array([[0.14303392, 0.85696608],\n",
       "          [0.33757169, 0.66242831],\n",
       "          [0.61021688, 0.38978312],\n",
       "          ...,\n",
       "          [0.84035457, 0.15964543],\n",
       "          [0.65554817, 0.34445183],\n",
       "          [0.30163083, 0.69836917]]),\n",
       "   'elapsed_time': 11.435251951217651},\n",
       "  'test_metrics': {'matrix': array([[23690,  5051],\n",
       "          [ 9282,  9977]]),\n",
       "   'auc': 0.6711507703622296,\n",
       "   'accuracy': 0.7014,\n",
       "   'precision': 0.6638940644130955,\n",
       "   'recall': 0.5180435121242016,\n",
       "   'f1': 0.5819698427975618,\n",
       "   'cost': -15.357291666666667,\n",
       "   'y_pred': array([1, 0, 0, ..., 0, 1, 0]),\n",
       "   'y_pred_proba': array([[0.34685109, 0.65314891],\n",
       "          [0.55278495, 0.44721505],\n",
       "          [0.8945538 , 0.1054462 ],\n",
       "          ...,\n",
       "          [0.72616872, 0.27383128],\n",
       "          [0.08231896, 0.91768104],\n",
       "          [0.86578602, 0.13421398]]),\n",
       "   'elapsed_time': 0.13938283920288086}},\n",
       " {'model': LogisticRegression(C=1, random_state=1, solver='liblinear'),\n",
       "  'train_metrics': {'matrix': array([[55509, 11553],\n",
       "          [21625, 23313]]),\n",
       "   'auc': 0.6732540067839653,\n",
       "   'accuracy': 0.70377,\n",
       "   'precision': 0.6686456720013767,\n",
       "   'recall': 0.5187814321954693,\n",
       "   'f1': 0.5842564282492105,\n",
       "   'cost': -15.1421875,\n",
       "   'y_pred': array([1, 1, 0, ..., 0, 0, 1]),\n",
       "   'y_pred_proba': array([[0.14450642, 0.85549358],\n",
       "          [0.33963591, 0.66036409],\n",
       "          [0.60773722, 0.39226278],\n",
       "          ...,\n",
       "          [0.84081065, 0.15918935],\n",
       "          [0.65769114, 0.34230886],\n",
       "          [0.29892223, 0.70107777]]),\n",
       "   'elapsed_time': 15.178524732589722},\n",
       "  'test_metrics': {'matrix': array([[23693,  5048],\n",
       "          [ 9297,  9962]]),\n",
       "   'auc': 0.6708135322938634,\n",
       "   'accuracy': 0.70115,\n",
       "   'precision': 0.663690872751499,\n",
       "   'recall': 0.517264655485747,\n",
       "   'f1': 0.581400099215034,\n",
       "   'cost': -15.358854166666667,\n",
       "   'y_pred': array([1, 0, 0, ..., 0, 1, 0]),\n",
       "   'y_pred_proba': array([[0.34812434, 0.65187566],\n",
       "          [0.54745716, 0.45254284],\n",
       "          [0.89601906, 0.10398094],\n",
       "          ...,\n",
       "          [0.72563056, 0.27436944],\n",
       "          [0.08196304, 0.91803696],\n",
       "          [0.86557781, 0.13442219]]),\n",
       "   'elapsed_time': 0.12344813346862793}},\n",
       " {'model': LogisticRegression(C=10, random_state=1, solver='liblinear'),\n",
       "  'train_metrics': {'matrix': array([[55500, 11562],\n",
       "          [21614, 23324]]),\n",
       "   'auc': 0.6733092955489423,\n",
       "   'accuracy': 0.70379,\n",
       "   'precision': 0.6685776529266755,\n",
       "   'recall': 0.5190262138946994,\n",
       "   'f1': 0.5843856484265384,\n",
       "   'cost': -15.147767857142858,\n",
       "   'y_pred': array([1, 1, 0, ..., 0, 0, 1]),\n",
       "   'y_pred_proba': array([[0.14358043, 0.85641957],\n",
       "          [0.3370297 , 0.6629703 ],\n",
       "          [0.60822619, 0.39177381],\n",
       "          ...,\n",
       "          [0.84075778, 0.15924222],\n",
       "          [0.65650377, 0.34349623],\n",
       "          [0.29933641, 0.70066359]]),\n",
       "   'elapsed_time': 14.298332929611206},\n",
       "  'test_metrics': {'matrix': array([[23693,  5048],\n",
       "          [ 9287,  9972]]),\n",
       "   'auc': 0.6710731511733483,\n",
       "   'accuracy': 0.70135,\n",
       "   'precision': 0.6639147802929427,\n",
       "   'recall': 0.5177838932447167,\n",
       "   'f1': 0.5818139385629686,\n",
       "   'cost': -15.353645833333333,\n",
       "   'y_pred': array([1, 0, 0, ..., 0, 1, 0]),\n",
       "   'y_pred_proba': array([[0.34739901, 0.65260099],\n",
       "          [0.54976429, 0.45023571],\n",
       "          [0.89421743, 0.10578257],\n",
       "          ...,\n",
       "          [0.72645963, 0.27354037],\n",
       "          [0.0821544 , 0.9178456 ],\n",
       "          [0.86604807, 0.13395193]]),\n",
       "   'elapsed_time': 0.1285560131072998}}]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=0.001, random_state=1, solver='liblinear'),\n",
       " 'train_metrics': {'matrix': array([[55387, 11675],\n",
       "         [21518, 23420]]),\n",
       "  'auc': 0.673534929921288,\n",
       "  'accuracy': 0.70363,\n",
       "  'precision': 0.6673315287077931,\n",
       "  'recall': 0.5211624905425253,\n",
       "  'f1': 0.5852585808354054,\n",
       "  'cost': -15.227232142857142,\n",
       "  'y_pred': array([1, 1, 0, ..., 0, 0, 1]),\n",
       "  'y_pred_proba': array([[0.14075395, 0.85924605],\n",
       "         [0.33423334, 0.66576666],\n",
       "         [0.61417412, 0.38582588],\n",
       "         ...,\n",
       "         [0.8398927 , 0.1601073 ],\n",
       "         [0.65163991, 0.34836009],\n",
       "         [0.30405237, 0.69594763]]),\n",
       "  'elapsed_time': 6.521888971328735},\n",
       " 'test_metrics': {'matrix': array([[23648,  5093],\n",
       "         [ 9243, 10016]]),\n",
       "  'auc': 0.6714326204801649,\n",
       "  'accuracy': 0.70133,\n",
       "  'precision': 0.6629161426964061,\n",
       "  'recall': 0.5200685393841841,\n",
       "  'f1': 0.5828677839851025,\n",
       "  'cost': -15.424479166666666,\n",
       "  'y_pred': array([1, 0, 0, ..., 0, 1, 0]),\n",
       "  'y_pred_proba': array([[0.34566391, 0.65433609],\n",
       "         [0.56366816, 0.43633184],\n",
       "         [0.89095928, 0.10904072],\n",
       "         ...,\n",
       "         [0.7267635 , 0.2732365 ],\n",
       "         [0.08251836, 0.91748164],\n",
       "         [0.86682084, 0.13317916]]),\n",
       "  'elapsed_time': 0.1322469711303711}}"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_modeling.find_best_model('auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NNTuningClassificationModeling(TuningClassificationModeling):\n",
    "#     TClass = None\n",
    "#     all_models = [];\n",
    "    \n",
    "#     def __init__(self, \n",
    "#              data: pd.DataFrame, \n",
    "#              target_name: str, \n",
    "#              shuffle_splitter: BaseShuffleSplit, \n",
    "#              imputer: BaseImputer, \n",
    "#              model: BaseModel, \n",
    "#              scaler = None,\n",
    "#              encoder = None,\n",
    "#              beta: int = 1, \n",
    "#              classification: str = 'binary',\n",
    "#                  classification_type: str = 'logistic'):\n",
    "#         super().__init__(data, target_name, shuffle_splitter, imputer, model, scaler, encoder, beta, classification, classification_type)\n",
    "#         if classification_type == 'neural':\n",
    "#             TClass = TypeVar(\"TClass\", bound=NNModel)\n",
    "                \n",
    "# #     def train(self, epoch, batch):\n",
    "# #         logDir = \"logs/{epoch}-{batchsize}-{time}\".format(epoch=epoch, batchsize=batch, time=time.time())\n",
    "# #         self.tb_callback.log_dir = logDir\n",
    "# #         self._model.fit(self.X_train, self.y_train, batch_size=batch, epochs=epoch, validation_data=(self.X_test, self.y_test), callbacks=[self.tb_callback])\n",
    "# #         self._y_preds = self._model.predict(self.X_train)\n",
    "# #         return self.metrics(self.y_train, self.y_preds)\n",
    "    \n",
    "# #     def metrics(self, y_true = None, y_pred = None):\n",
    "# #         if y_true is None and y_pred is None:\n",
    "# #             y_true = self.y_train\n",
    "# #             y_pred = self.y_preds\n",
    "            \n",
    "# #         y_pred_proba= pd.Series(y_pred.reshape((y_pred.shape[1], y_pred.shape[0]))[0], index=y_true.index)\n",
    "# #         y_pred = pd.Series( (y_pred_proba>0.5).astype(int), index=y_true.index)\n",
    "# #         return super().metrics(y_true,y_pred, y_pred_proba)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel:\n",
    "    model = None\n",
    "    epoch = 50\n",
    "    batch_size = 32\n",
    "    loss = 'BinaryCrossentropy',\n",
    "    metric = 'accuracy'\n",
    "    optimizer = 'adam'\n",
    "    \n",
    "    def __init__(self,**inputs):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        for arg, content in inputs.items():\n",
    "            if arg.startswith('input'):\n",
    "                self.model.add( tf.keras.layers.Input( shape=(content,) ) )\n",
    "            if arg.startswith('layer'):\n",
    "                self.model.add( tf.keras.layers.Dense(content['s'], activation = content['activation']) )\n",
    "            if arg == 'epoch':\n",
    "                self.epoch = content\n",
    "            if arg == 'bs':\n",
    "                self.batch_size = content\n",
    "            if arg == 'optimizer':\n",
    "                self.optimizer = content\n",
    "            if arg == 'loss':\n",
    "                self.loss = content\n",
    "            if arg == 'metric':\n",
    "                self.metric = content\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss, metrics=[self.metric])\n",
    "        print(self.model)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epoch)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        return pd.Series( (y_pred_proba>0.5).astype(int))\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_pred_proba = self.model.predict(X)\n",
    "        return pd.Series(y_pred_proba.reshape((y_pred_proba.shape[1], y_pred_proba.shape[0]))[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7ff6c56de490>\n"
     ]
    }
   ],
   "source": [
    "mynn= NNModel(input=67,\n",
    "        layer1={'s':300, 'activation': 'relu'}, \n",
    "        layer2={'s':200, 'activation': 'relu'}, \n",
    "        layer3={'s':100, 'activation': 'relu'},\n",
    "        layer4={'s':1, 'activation':'sigmoid'},\n",
    "        loss='BinaryCrossentropy',\n",
    "        metric='accuracy',\n",
    "        epoch=30,\n",
    "        bs=100, \n",
    "        optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 300)               20400     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 100,801\n",
      "Trainable params: 100,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mynn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_modeling = TuningClassificationModeling(loader.get_df(),'y',\n",
    "                                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                           SimpleImputer(missing_values=np.nan, strategy='mean'), NNModel, None, LabelEncoder(), beta=1,classification_type='neural' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_modeling.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 50, 'layer1': {'s': 300, 'activation': 'relu'}, 'layer2': {'s': 200, 'activation': 'relu'}, 'layer3': {'s': 100, 'activation': 'relu'}, 'layer4': {'s': 1, 'activation': 'sigmoid'}, 'loss': 'BinaryCrossentropy', 'metric': 'accuracy', 'epoch': 10, 'optimizer': 'adam'}\n",
      "<keras.engine.sequential.Sequential object at 0x7ff69437a700>\n",
      "<keras.engine.sequential.Sequential object at 0x7ff69434f0a0>\n",
      "Epoch 1/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.6527 - accuracy: 0.7903\n",
      "Epoch 2/10\n",
      "1120/1120 [==============================] - 2s 2ms/step - loss: 0.3024 - accuracy: 0.8748\n",
      "Epoch 3/10\n",
      "1120/1120 [==============================] - 2s 2ms/step - loss: 0.2514 - accuracy: 0.8995\n",
      "Epoch 4/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.2241 - accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.1969 - accuracy: 0.9242\n",
      "Epoch 6/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.1770 - accuracy: 0.9329\n",
      "Epoch 7/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.1610 - accuracy: 0.9411\n",
      "Epoch 8/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.1460 - accuracy: 0.9466\n",
      "Epoch 9/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.1372 - accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.1288 - accuracy: 0.9549\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 2.1436 - accuracy: 0.7024\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4572 - accuracy: 0.7996\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4100 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3666 - accuracy: 0.8488\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3238 - accuracy: 0.8661\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2859 - accuracy: 0.8835\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2685 - accuracy: 0.8912\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2491 - accuracy: 0.8999\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2642 - accuracy: 0.8945\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2244 - accuracy: 0.9112\n"
     ]
    }
   ],
   "source": [
    "nn_model_tunning = nn_modeling.parameter_tuning( { \n",
    "        'input':50,\n",
    "        'layer1':{'s':300, 'activation': 'relu'}, \n",
    "        'layer2':{'s':200, 'activation': 'relu'}, \n",
    "        'layer3':{'s':100, 'activation': 'relu'},\n",
    "        'layer4':{'s':1, 'activation':'sigmoid'},\n",
    "        'loss':'BinaryCrossentropy',\n",
    "        'metric':'accuracy',\n",
    "        'epoch':10,\n",
    "        'bs':[100,1000], \n",
    "        'optimizer':'adam'\n",
    " }, NNModel)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': <__main__.NNModel at 0x7ff69437abb0>,\n",
       "  'train_metrics': {'matrix': array([[64138,  2924],\n",
       "          [ 2132, 42806]]),\n",
       "   'auc': 0.9544777063362342,\n",
       "   'accuracy': 0.95486,\n",
       "   'precision': 0.9360594795539033,\n",
       "   'recall': 0.9525568561128667,\n",
       "   'f1': 0.9442361141747916,\n",
       "   'cost': -3.086607142857143,\n",
       "   'y_pred': 0         0\n",
       "   1         0\n",
       "   2         1\n",
       "   3         0\n",
       "   4         0\n",
       "            ..\n",
       "   111995    1\n",
       "   111996    1\n",
       "   111997    0\n",
       "   111998    0\n",
       "   111999    1\n",
       "   Length: 112000, dtype: int64,\n",
       "   'y_pred_proba': 0         0.019525\n",
       "   1         0.021994\n",
       "   2         0.873751\n",
       "   3         0.001637\n",
       "   4         0.066766\n",
       "               ...   \n",
       "   111995    0.955188\n",
       "   111996    0.968965\n",
       "   111997    0.001305\n",
       "   111998    0.004798\n",
       "   111999    0.998538\n",
       "   Length: 112000, dtype: float32,\n",
       "   'elapsed_time': 29.768935918807983},\n",
       "  'test_metrics': {'matrix': array([[27309,  1432],\n",
       "          [ 1090, 18169]]),\n",
       "   'auc': 0.9467893957250937,\n",
       "   'accuracy': 0.94746,\n",
       "   'precision': 0.9269425029335238,\n",
       "   'recall': 0.9434030842722883,\n",
       "   'f1': 0.9351003602676274,\n",
       "   'cost': -3.551041666666667,\n",
       "   'y_pred': 0        0\n",
       "   1        1\n",
       "   2        1\n",
       "   3        1\n",
       "   4        0\n",
       "           ..\n",
       "   47995    1\n",
       "   47996    0\n",
       "   47997    0\n",
       "   47998    1\n",
       "   47999    0\n",
       "   Length: 48000, dtype: int64,\n",
       "   'y_pred_proba': 0        0.284474\n",
       "   1        0.616883\n",
       "   2        0.979526\n",
       "   3        0.991031\n",
       "   4        0.003321\n",
       "              ...   \n",
       "   47995    0.974243\n",
       "   47996    0.000018\n",
       "   47997    0.001299\n",
       "   47998    0.999883\n",
       "   47999    0.020667\n",
       "   Length: 48000, dtype: float32,\n",
       "   'elapsed_time': 1.8496031761169434}},\n",
       " {'model': <__main__.NNModel at 0x7ff69437aa00>,\n",
       "  'train_metrics': {'matrix': array([[55374, 11688],\n",
       "          [ 4600, 40338]]),\n",
       "   'auc': 0.8616751313958305,\n",
       "   'accuracy': 0.85457,\n",
       "   'precision': 0.7753430976819282,\n",
       "   'recall': 0.8976367439583426,\n",
       "   'f1': 0.832020131182707,\n",
       "   'cost': -11.4625,\n",
       "   'y_pred': 0         0\n",
       "   1         0\n",
       "   2         1\n",
       "   3         0\n",
       "   4         0\n",
       "            ..\n",
       "   111995    0\n",
       "   111996    1\n",
       "   111997    0\n",
       "   111998    0\n",
       "   111999    1\n",
       "   Length: 112000, dtype: int64,\n",
       "   'y_pred_proba': 0         0.034466\n",
       "   1         0.077174\n",
       "   2         0.655183\n",
       "   3         0.017927\n",
       "   4         0.036065\n",
       "               ...   \n",
       "   111995    0.475579\n",
       "   111996    0.896442\n",
       "   111997    0.000001\n",
       "   111998    0.044872\n",
       "   111999    0.998936\n",
       "   Length: 112000, dtype: float32,\n",
       "   'elapsed_time': 14.64121389389038},\n",
       "  'test_metrics': {'matrix': array([[23560,  5181],\n",
       "          [ 2160, 17099]]),\n",
       "   'auc': 0.8537897587940707,\n",
       "   'accuracy': 0.84706,\n",
       "   'precision': 0.76745960502693,\n",
       "   'recall': 0.8878446440625162,\n",
       "   'f1': 0.8232745131081635,\n",
       "   'cost': -11.91875,\n",
       "   'y_pred': 0        0\n",
       "   1        1\n",
       "   2        1\n",
       "   3        1\n",
       "   4        0\n",
       "           ..\n",
       "   47995    1\n",
       "   47996    0\n",
       "   47997    0\n",
       "   47998    1\n",
       "   47999    0\n",
       "   Length: 48000, dtype: int64,\n",
       "   'y_pred_proba': 0        0.480685\n",
       "   1        0.893913\n",
       "   2        0.915864\n",
       "   3        0.926991\n",
       "   4        0.172296\n",
       "              ...   \n",
       "   47995    0.505637\n",
       "   47996    0.044930\n",
       "   47997    0.001691\n",
       "   47998    0.999955\n",
       "   47999    0.063958\n",
       "   Length: 48000, dtype: float32,\n",
       "   'elapsed_time': 2.0661838054656982}}]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_modeling.find_best_model()['model'].batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <__main__.NNModel at 0x7ff69437abb0>,\n",
       " 'train_metrics': {'matrix': array([[64138,  2924],\n",
       "         [ 2132, 42806]]),\n",
       "  'auc': 0.9544777063362342,\n",
       "  'accuracy': 0.95486,\n",
       "  'precision': 0.9360594795539033,\n",
       "  'recall': 0.9525568561128667,\n",
       "  'f1': 0.9442361141747916,\n",
       "  'cost': -3.086607142857143,\n",
       "  'y_pred': 0         0\n",
       "  1         0\n",
       "  2         1\n",
       "  3         0\n",
       "  4         0\n",
       "           ..\n",
       "  111995    1\n",
       "  111996    1\n",
       "  111997    0\n",
       "  111998    0\n",
       "  111999    1\n",
       "  Length: 112000, dtype: int64,\n",
       "  'y_pred_proba': 0         0.019525\n",
       "  1         0.021994\n",
       "  2         0.873751\n",
       "  3         0.001637\n",
       "  4         0.066766\n",
       "              ...   \n",
       "  111995    0.955188\n",
       "  111996    0.968965\n",
       "  111997    0.001305\n",
       "  111998    0.004798\n",
       "  111999    0.998538\n",
       "  Length: 112000, dtype: float32,\n",
       "  'elapsed_time': 29.768935918807983},\n",
       " 'test_metrics': {'matrix': array([[27309,  1432],\n",
       "         [ 1090, 18169]]),\n",
       "  'auc': 0.9467893957250937,\n",
       "  'accuracy': 0.94746,\n",
       "  'precision': 0.9269425029335238,\n",
       "  'recall': 0.9434030842722883,\n",
       "  'f1': 0.9351003602676274,\n",
       "  'cost': -3.551041666666667,\n",
       "  'y_pred': 0        0\n",
       "  1        1\n",
       "  2        1\n",
       "  3        1\n",
       "  4        0\n",
       "          ..\n",
       "  47995    1\n",
       "  47996    0\n",
       "  47997    0\n",
       "  47998    1\n",
       "  47999    0\n",
       "  Length: 48000, dtype: int64,\n",
       "  'y_pred_proba': 0        0.284474\n",
       "  1        0.616883\n",
       "  2        0.979526\n",
       "  3        0.991031\n",
       "  4        0.003321\n",
       "             ...   \n",
       "  47995    0.974243\n",
       "  47996    0.000018\n",
       "  47997    0.001299\n",
       "  47998    0.999883\n",
       "  47999    0.020667\n",
       "  Length: 48000, dtype: float32,\n",
       "  'elapsed_time': 1.8496031761169434}}"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_modeling.find_best_model('auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_cost_proba(train_proba, test_proba, y_train, y_test, conf_train, conf_test):\n",
    "    cost_results = pd.DataFrame()\n",
    "    thresh = 0\n",
    "    for i in range(11):\n",
    "        yhat_train = pd.Series(train_proba < thresh).astype(int)\n",
    "        yhat_test = pd.Series(test_proba < thresh).astype(int)\n",
    "        conf_train = confusion_matrix(y_train, yhat_train)\n",
    "        conf_test = confusion_matrix(y_test, yhat_test)\n",
    "        cost_results = cost_results.append({\"Threshold\": thresh,\n",
    "                                        \"Train Cost\": -TuningClassificationModeling.cost_calc(conf_train),\n",
    "                                        \"Test Cost\":  -TuningClassificationModeling.cost_calc(conf_test)},\n",
    "                                        ignore_index=True)\n",
    "        thresh = thresh + 0.05\n",
    "    return cost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14075395, 0.85924605],\n",
       "       [0.33423334, 0.66576666],\n",
       "       [0.61417412, 0.38582588],\n",
       "       ...,\n",
       "       [0.8398927 , 0.1601073 ],\n",
       "       [0.65163991, 0.34836009],\n",
       "       [0.30405237, 0.69594763]])"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_modeling.find_best_model('auc')['train_metrics']['y_pred_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34566391, 0.65433609],\n",
       "       [0.56366816, 0.43633184],\n",
       "       [0.89095928, 0.10904072],\n",
       "       ...,\n",
       "       [0.7267635 , 0.2732365 ],\n",
       "       [0.08251836, 0.91748164],\n",
       "       [0.86682084, 0.13317916]])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_modeling.find_best_model('auc')['test_metrics']['y_pred_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67652     0\n",
       "73756     1\n",
       "137380    1\n",
       "8186      1\n",
       "25244     0\n",
       "         ..\n",
       "148081    1\n",
       "52534     0\n",
       "89420     0\n",
       "70022     1\n",
       "92035     1\n",
       "Name: y, Length: 48000, dtype: int64"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_modeling.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba = linear_modeling.find_best_model('auc')['train_metrics']['y_pred_proba']\n",
    "test_proba = linear_modeling.find_best_model('auc')['test_metrics']['y_pred_proba']\n",
    "conf_train = linear_modeling.find_best_model('auc')['train_metrics']['matrix']\n",
    "conf_test = linear_modeling.find_best_model('auc')['test_metrics']['matrix']\n",
    "   \n",
    "cost_results = tune_cost_proba(train_proba[:,0], test_proba[:,0], linear_modeling.y_train, linear_modeling.y_test, conf_train, conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba = nn_modeling.find_best_model('auc')['train_metrics']['y_pred_proba']\n",
    "test_proba = nn_modeling.find_best_model('auc')['test_metrics']['y_pred_proba']\n",
    "conf_train = nn_modeling.find_best_model('auc')['train_metrics']['matrix']\n",
    "conf_test = nn_modeling.find_best_model('auc')['test_metrics']['matrix']\n",
    "\n",
    "cost_results = tune_cost_proba(1-train_proba, 1-test_proba, nn_modeling.y_train, nn_modeling.y_test, conf_train, conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Cost</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Train Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.030729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.030804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.471354</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.322545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.850521</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.563170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.590625</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.269420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.560417</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.185491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.596875</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.180357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.739063</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.260937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.885417</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.387946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.064062</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.583705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.301042</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.826116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.551042</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.086607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Cost  Threshold  Train Cost\n",
       "0   10.030729       0.00   10.030804\n",
       "1    3.471354       0.05    3.322545\n",
       "2    2.850521       0.10    2.563170\n",
       "3    2.590625       0.15    2.269420\n",
       "4    2.560417       0.20    2.185491\n",
       "5    2.596875       0.25    2.180357\n",
       "6    2.739063       0.30    2.260937\n",
       "7    2.885417       0.35    2.387946\n",
       "8    3.064062       0.40    2.583705\n",
       "9    3.301042       0.45    2.826116\n",
       "10   3.551042       0.50    3.086607"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add input\n",
      "add layer\n",
      "add layer\n",
      "add layer\n",
      "set epoch\n",
      "set bs\n"
     ]
    }
   ],
   "source": [
    "sample_multiargument(input=67,layer1=300, layer2=200, layer3=100, epoch=30, bs=100, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = TuningClassificationModeling(loader.get_df(),'y',\n",
    "                                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                           None, XGBClassifier, None, LabelEncoder(), beta=1,classification_type = 'xgb' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "[21:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_results = xgb_classifier.parameter_tuning( { \n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [100],\n",
    "    'colsample_bytree': [0.3],\n",
    " }, XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=0.3,\n",
       "                enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "                importance_type=None, interaction_constraints='',\n",
       "                learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                subsample=1, tree_method='exact', validate_parameters=1,\n",
       "                verbosity=None),\n",
       "  'train_metrics': {'matrix': array([[60663,  6399],\n",
       "          [12781, 32157]]),\n",
       "   'accuracy': 0.82875,\n",
       "   'precision': 0.8340336134453782,\n",
       "   'recall': 0.7155859183764297,\n",
       "   'f1': 0.7702828945792514,\n",
       "   'cost': -8.566294642857143,\n",
       "   'y_pred': array([1, 0, 0, ..., 0, 0, 0]),\n",
       "   'y_pred_proba': array([[0.44765896, 0.55234104],\n",
       "          [0.70319164, 0.29680836],\n",
       "          [0.7852705 , 0.21472947],\n",
       "          ...,\n",
       "          [0.903553  , 0.09644701],\n",
       "          [0.8099411 , 0.1900589 ],\n",
       "          [0.51155674, 0.48844323]], dtype=float32),\n",
       "   'elapsed_time': 15.13117504119873},\n",
       "  'test_metrics': {'matrix': array([[25890,  2851],\n",
       "          [ 5630, 13629]]),\n",
       "   'accuracy': 0.82331,\n",
       "   'precision': 0.827002427184466,\n",
       "   'recall': 0.7076691416999844,\n",
       "   'f1': 0.76269621421976,\n",
       "   'cost': -8.871875,\n",
       "   'y_pred': array([1, 1, 1, ..., 0, 1, 0]),\n",
       "   'y_pred_proba': array([[0.37489408, 0.6251059 ],\n",
       "          [0.3999843 , 0.6000157 ],\n",
       "          [0.29097462, 0.7090254 ],\n",
       "          ...,\n",
       "          [0.8086082 , 0.1913918 ],\n",
       "          [0.09379804, 0.90620196],\n",
       "          [0.89241713, 0.10758288]], dtype=float32),\n",
       "   'elapsed_time': 0.2374589443206787}}]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31724763, 0.6827524 ],\n",
       "       [0.4503014 , 0.5496986 ],\n",
       "       [0.380547  , 0.619453  ],\n",
       "       ...,\n",
       "       [0.70762724, 0.29237276],\n",
       "       [0.17255515, 0.82744485],\n",
       "       [0.86919796, 0.13080207]], dtype=float32)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results[0]['model'].predict_proba(xgb_classifier.X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
