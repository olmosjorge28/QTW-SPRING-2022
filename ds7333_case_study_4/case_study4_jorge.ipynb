{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import warnings\\nwarnings.filterwarnings('ignore')\\nfrom warnings import simplefilter \\nsimplefilter(action='ignore', category=FutureWarning)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import re\n",
    "import os\n",
    "from IPython.display import Image\n",
    "#import sklearn\n",
    "#import time\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# data pre-processing\n",
    "from scipy.io import arff\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.impute._base import _BaseImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection._split import BaseShuffleSplit\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# prediction models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# import warnings filter\n",
    "'''import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "class FilePathManager:\n",
    "    def __init__(self, local_dir: str):\n",
    "        self.local_dir = local_dir\n",
    "    \n",
    "    def retrieve_full_path(self):\n",
    "        return os.getcwd()+'/'+self.local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARFFLoader:\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, file_path_manager: FilePathManager):\n",
    "        self.file_path_manager = file_path_manager\n",
    "    \n",
    "    def load_data(self):\n",
    "        files = self.retrieve_files()\n",
    "        for file in files:\n",
    "            self.df = pd.concat([self.df, self.load_file(file)])\n",
    "        self.df=self.df.reset_index(drop=True)\n",
    "        \n",
    "    def load_file(self, file_name):\n",
    "        return pd.DataFrame(arff.loadarff(self.file_path_manager.retrieve_full_path()+'/'+file_name)[0])\n",
    " \n",
    "    def retrieve_files(self):\n",
    "        full_path = self.file_path_manager.retrieve_full_path()\n",
    "        return [f for f in os.listdir(full_path) if os.path.isfile(join(full_path, f))]\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df;\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df: pd.DataFrame):\n",
    "    df['bankrupt'] = ( df['class'] == df['class'][df.shape[0]-1] ).astype(int)\n",
    "    df = df.drop('class', axis=1)\n",
    "    return df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_manager = FilePathManager('data')\n",
    "loader = ARFFLoader(path_manager)\n",
    "loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.51710</td>\n",
       "      <td>-14.5470</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>0.918160</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.426950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131840</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.34400</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.33820</td>\n",
       "      <td>-37.8590</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.678900</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.404370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.23810</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.22110</td>\n",
       "      <td>71.7990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318770</td>\n",
       "      <td>2.332000</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.698410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164990</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.46600</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.08280</td>\n",
       "      <td>-88.2120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285050</td>\n",
       "      <td>0.473840</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293580</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.00660</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.94440</td>\n",
       "      <td>21.7310</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.108230</td>\n",
       "      <td>1.371400</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.521670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101240</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.98740</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43400</th>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>-0.136190</td>\n",
       "      <td>0.60839</td>\n",
       "      <td>-18.4490</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.972030</td>\n",
       "      <td>1.01210</td>\n",
       "      <td>0.460840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>0.98809</td>\n",
       "      <td>0.27414</td>\n",
       "      <td>73.5050</td>\n",
       "      <td>79.23700</td>\n",
       "      <td>31.268</td>\n",
       "      <td>11.67300</td>\n",
       "      <td>5.14890</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43401</th>\n",
       "      <td>-0.013359</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>-0.022650</td>\n",
       "      <td>0.92896</td>\n",
       "      <td>-42.2320</td>\n",
       "      <td>-0.013359</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.562890</td>\n",
       "      <td>0.98904</td>\n",
       "      <td>0.328470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.040671</td>\n",
       "      <td>1.01110</td>\n",
       "      <td>0.80592</td>\n",
       "      <td>10.5990</td>\n",
       "      <td>7.17400</td>\n",
       "      <td>94.092</td>\n",
       "      <td>3.87920</td>\n",
       "      <td>1.75720</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43402</th>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.50276</td>\n",
       "      <td>0.439230</td>\n",
       "      <td>1.87360</td>\n",
       "      <td>9.7417</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.983560</td>\n",
       "      <td>1.00830</td>\n",
       "      <td>0.494490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.99174</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.4700</td>\n",
       "      <td>6.07590</td>\n",
       "      <td>51.019</td>\n",
       "      <td>7.15420</td>\n",
       "      <td>62.00100</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>-0.041643</td>\n",
       "      <td>0.84810</td>\n",
       "      <td>-0.128520</td>\n",
       "      <td>0.57485</td>\n",
       "      <td>-121.9200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036795</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>0.42138</td>\n",
       "      <td>0.151820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232720</td>\n",
       "      <td>-0.274290</td>\n",
       "      <td>0.98788</td>\n",
       "      <td>3.59310</td>\n",
       "      <td>39.7030</td>\n",
       "      <td>3.14200</td>\n",
       "      <td>261.850</td>\n",
       "      <td>1.39390</td>\n",
       "      <td>0.51005</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.94648</td>\n",
       "      <td>0.032110</td>\n",
       "      <td>1.03630</td>\n",
       "      <td>-20.5810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>2.96940</td>\n",
       "      <td>0.053341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.280210</td>\n",
       "      <td>0.97443</td>\n",
       "      <td>1.17920</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>4.17410</td>\n",
       "      <td>108.640</td>\n",
       "      <td>3.35990</td>\n",
       "      <td>35.11800</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43405 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Attr1    Attr2     Attr3    Attr4     Attr5     Attr6     Attr7  \\\n",
       "0      0.202350  0.46500  0.240380  1.51710  -14.5470  0.510690  0.253660   \n",
       "1      0.030073  0.59563  0.186680  1.33820  -37.8590 -0.000319  0.041670   \n",
       "2      0.257860  0.29949  0.665190  3.22110   71.7990  0.000000  0.318770   \n",
       "3      0.227160  0.67850  0.042784  1.08280  -88.2120  0.000000  0.285050   \n",
       "4      0.085443  0.38039  0.359230  1.94440   21.7310  0.187900  0.108230   \n",
       "...         ...      ...       ...      ...       ...       ...       ...   \n",
       "43400  0.018371  0.47410 -0.136190  0.60839  -18.4490  0.018371  0.018371   \n",
       "43401 -0.013359  0.58354 -0.022650  0.92896  -42.2320 -0.013359 -0.015036   \n",
       "43402  0.006338  0.50276  0.439230  1.87360    9.7417  0.006338  0.012022   \n",
       "43403 -0.041643  0.84810 -0.128520  0.57485 -121.9200  0.000000 -0.036795   \n",
       "43404  0.014946  0.94648  0.032110  1.03630  -20.5810  0.000000  0.015260   \n",
       "\n",
       "          Attr8    Attr9    Attr10  ...    Attr56    Attr57   Attr58   Attr59  \\\n",
       "0      0.918160  1.15190  0.426950  ...  0.131840  0.473950  0.86816  0.00024   \n",
       "1      0.678900  0.32356  0.404370  ...  0.121460  0.074369  0.87235  0.00000   \n",
       "2      2.332000  1.67620  0.698410  ...  0.164990  0.369210  0.81614  0.00000   \n",
       "3      0.473840  1.32410  0.321500  ...  0.293580  0.706570  0.78617  0.48456   \n",
       "4      1.371400  1.11260  0.521670  ...  0.101240  0.163790  0.89876  0.00000   \n",
       "...         ...      ...       ...  ...       ...       ...      ...      ...   \n",
       "43400  0.972030  1.01210  0.460840  ...  0.011909  0.039866  0.98809  0.27414   \n",
       "43401  0.562890  0.98904  0.328470  ... -0.011082 -0.040671  1.01110  0.80592   \n",
       "43402  0.983560  1.00830  0.494490  ...  0.008258  0.012817  0.99174  0.00000   \n",
       "43403  0.179010  0.42138  0.151820  ... -0.232720 -0.274290  0.98788  3.59310   \n",
       "43404  0.056357  2.96940  0.053341  ...  0.015705  0.280210  0.97443  1.17920   \n",
       "\n",
       "        Attr60    Attr61   Attr62    Attr63    Attr64  class  \n",
       "0       8.5487   5.16550  107.740   3.38790   5.34400   b'0'  \n",
       "1       1.5264   0.63305  622.660   0.58619   1.23810   b'0'  \n",
       "2       4.3325   3.19850   65.215   5.59690  47.46600   b'0'  \n",
       "3       5.2309   5.06750  142.460   2.56210   3.00660   b'0'  \n",
       "4       5.7035   4.00200   89.058   4.09840   5.98740   b'0'  \n",
       "...        ...       ...      ...       ...       ...    ...  \n",
       "43400  73.5050  79.23700   31.268  11.67300   5.14890   b'1'  \n",
       "43401  10.5990   7.17400   94.092   3.87920   1.75720   b'1'  \n",
       "43402  10.4700   6.07590   51.019   7.15420  62.00100   b'1'  \n",
       "43403  39.7030   3.14200  261.850   1.39390   0.51005   b'1'  \n",
       "43404  15.0360   4.17410  108.640   3.35990  35.11800   b'1'  \n",
       "\n",
       "[43405 rows x 65 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'    41314\n",
       "b'1'     2091\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_df()['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04817417348231771"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2091/(41314+2091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2091/(2091+0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09192016880604888"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*(1*(.04817417348231771*1.0)))/(.04817417348231771+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attr37    43.736897\n",
       "Attr21    13.486925\n",
       "Attr27     6.367930\n",
       "Attr60     4.957954\n",
       "Attr45     4.946435\n",
       "Attr24     2.124179\n",
       "Attr28     1.870752\n",
       "Attr64     1.870752\n",
       "Attr54     1.870752\n",
       "Attr53     1.870752\n",
       "Attr41     1.737127\n",
       "Attr32     0.847829\n",
       "Attr52     0.693468\n",
       "Attr47     0.684253\n",
       "Attr46     0.311024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = loader.get_df().isnull().sum()\n",
    "pct_missing = missing/loader.size()*100\n",
    "pct_missing.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseImputer:\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def transform(self, X):\n",
    "        pass\n",
    "\n",
    "class BaseModel:\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBModel:\n",
    "    _model = None\n",
    "    \n",
    "    def __init__(self, params, num_round: int = 100):\n",
    "        self._params = params\n",
    "        self._num_round = num_round\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        dtrain = xgb.DMatrix(X, label = y)\n",
    "        self._model = xgb.train(self._params, dtrain)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self._model.predict(dtest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModeling(Modeling):\n",
    "    def __init__(self, \n",
    "                 data: pd.DataFrame, \n",
    "                 target_name: str, \n",
    "                 shuffle_splitter: BaseShuffleSplit, \n",
    "                 imputer: BaseImputer, \n",
    "                 model: BaseModel, \n",
    "                 scaler = None, \n",
    "                 beta: int = 1, \n",
    "                 classification: str = 'binary'):\n",
    "        super().__init__(data, target_name, shuffle_splitter, imputer, model, scaler)\n",
    "        self.beta = beta\n",
    "        self.classification = classification\n",
    "    \n",
    "    \n",
    "    def metrics(self, y_true = None, y_pred = None):\n",
    "        if y_true is None and y_pred is None:\n",
    "            y_true = self.y_train\n",
    "            y_pred = self.y_preds\n",
    "        return ({ 'matrix': confusion_matrix(y_true, y_pred), \n",
    "                'accuracy': accuracy_score(y_true, y_pred), \n",
    "                'precision': precision_score(y_true, y_pred, average=self.classification), \n",
    "                'recall': recall_score(y_true, y_pred, average=self.classification),\n",
    "                 'f1': f1_score(y_true, y_pred),\n",
    "                'f{}'.format(self.beta) : fbeta_score(y_true, y_pred, average=self.classification, beta=self.beta) } )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling:\n",
    "    _X_train_fitted = None\n",
    "    _X_test_fitted = None\n",
    "    _y_train = None\n",
    "    _y_test = None\n",
    "    _y_preds = None\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                 target_name: str, \n",
    "                 shuffle_splitter: BaseShuffleSplit, \n",
    "                 imputer: BaseImputer, \n",
    "                 model: BaseModel, scaler = None):\n",
    "        self._data = data\n",
    "        self._target_name = target_name\n",
    "        self._shuffle_splitter = shuffle_splitter\n",
    "        self._imputer = imputer\n",
    "        self._model = model\n",
    "        self._X, self._y = self._split_data()\n",
    "        self._scaler = scaler\n",
    "        \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self._model = model\n",
    "     \n",
    "    @property\n",
    "    def X_train(self):\n",
    "        return self._X_train_fitted\n",
    "    \n",
    "    @property\n",
    "    def X_test(self):\n",
    "        return self._X_test_fitted\n",
    "    \n",
    "    @property\n",
    "    def y_train(self):\n",
    "        return self._y_train\n",
    "    \n",
    "    @property\n",
    "    def y_test(self):\n",
    "        return self._y_test\n",
    "    \n",
    "    @property\n",
    "    def y_preds(self):\n",
    "        return self._y_preds\n",
    "    \n",
    "    def _split_data(self):\n",
    "        X = self._data.copy()\n",
    "        return X.drop([self._target_name], axis=1) , X[self._target_name]\n",
    "    \n",
    "    def _shuffle_split(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        for train_index, test_index in self._shuffle_splitter.split(X,y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def _fit_imputer(self, train):\n",
    "        if self._imputer is not None:\n",
    "            self._imputer.fit(train)\n",
    "    \n",
    "    def _fit_scaler(self, train):\n",
    "        if self._scaler is not None:\n",
    "            self._scaler.fit(train)\n",
    "    \n",
    "    def _impute_data(self, X: pd.DataFrame):\n",
    "        if self._imputer is not None:\n",
    "            return pd.DataFrame(self._imputer.transform(X), columns = self.X.columns, index = X.index)\n",
    "        return X\n",
    "    \n",
    "    def _scale_data(self, X: pd.DataFrame):\n",
    "        if self._scaler is not None:\n",
    "            X = pd.DataFrame(self._scaler.transform(X), columns = self._X.columns)\n",
    "        return X\n",
    "    \n",
    "    def prepare(self):\n",
    "        X_train, X_test, y_train, y_test = self._shuffle_split()   \n",
    "        self._fit_imputer(X_train)\n",
    "        X_train = self._impute_data(X_train)\n",
    "        X_test = self._impute_data(X_test)\n",
    "        self._fit_scaler(X_train)\n",
    "        self._X_train_fitted = self._scale_data(X_train)\n",
    "        self._X_test_fitted = self._scale_data(X_test)\n",
    "        self._y_train = y_train\n",
    "        self._y_test = y_test\n",
    "        \n",
    "    def prepare_and_train(self):\n",
    "        self.prepare()\n",
    "        return self.train()\n",
    "        \n",
    "    def train(self):\n",
    "        self._model.fit(self.X_train, self.y_train)\n",
    "        self._y_preds = self._model.predict(self.X_train)\n",
    "        \n",
    "        return self.metrics(self.y_train, self.y_preds)\n",
    "        \n",
    "    def test(self):\n",
    "        return self.metrics(self.y_test, self._model.predict(self.X_test))\n",
    "    \n",
    "    @abstractmethod\n",
    "    def metrics(self, y_true = None, y_pred = None):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_impute_model = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                               StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                               SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "                               RandomForestClassifier(random_state=0, class_weight={0: .024, 1: .976}, max_depth=13),\n",
    "                               StandardScaler(), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[27416,  1503],\n",
       "        [    2,  1462]]),\n",
       " 'accuracy': 0.9504657209623802,\n",
       " 'precision': 0.49308600337268127,\n",
       " 'recall': 0.9986338797814208,\n",
       " 'f1': 0.6601941747572816,\n",
       " 'f2': 0.8287042285455163}"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_impute_model.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[11645,   750],\n",
       "        [  276,   351]]),\n",
       " 'accuracy': 0.9212102595607433,\n",
       " 'precision': 0.3188010899182561,\n",
       " 'recall': 0.5598086124401914,\n",
       " 'f1': 0.40625,\n",
       " 'f2': 0.48628428927680795}"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_impute_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_impute_model = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                               StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                               IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                               RandomForestClassifier(random_state=0, class_weight={0: .02, 1: .98}, max_depth=13),\n",
    "                               StandardScaler(), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[27101,  1818],\n",
       "        [    1,  1463]]),\n",
       " 'accuracy': 0.9401309943060264,\n",
       " 'precision': 0.4459006400487656,\n",
       " 'recall': 0.9993169398907104,\n",
       " 'f1': 0.6166491043203371,\n",
       " 'f2': 0.8005910036116887}"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_impute_model.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[11501,   894],\n",
       "        [  236,   391]]),\n",
       " 'accuracy': 0.9132237751497466,\n",
       " 'precision': 0.3042801556420233,\n",
       " 'recall': 0.6236044657097288,\n",
       " 'f1': 0.4089958158995815,\n",
       " 'f2': 0.5154231479040337}"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_impute_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_impute_model = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                            StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=1234),\n",
    "                            KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean'),\n",
    "                            RandomForestClassifier(random_state=0, class_weight='balanced'),\n",
    "                            StandardScaler(), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_impute_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_impute_model._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_impute_model._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9524650591307019, 0.09635036496350363)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_impute_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB todo: figure out how to run class_weight with xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 1000\n",
    "params = {\n",
    "    'max_depth': 15,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_simple_imputer = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                                            StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                            SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "                                            XGBModel(params, num_round),\n",
    "                                            StandardScaler(),\n",
    "                                            beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_simple_imputer.prepare_and_train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[28919,     0],\n",
       "        [   66,  1398]]),\n",
       " 'accuracy': 0.9978277326136327,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.9549180327868853,\n",
       " 'f1': 0.9769392033542976,\n",
       " 'f2': 0.9636062861869312}"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_simple_imputer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[12370,    25],\n",
       "        [  313,   314]]),\n",
       " 'accuracy': 0.9740439256642605,\n",
       " 'precision': 0.9262536873156342,\n",
       " 'recall': 0.5007974481658692,\n",
       " 'f1': 0.650103519668737,\n",
       " 'f2': 0.551457674745346}"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_simple_imputer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    'max_depth': 15,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_iterative_imputer = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                                 StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                 IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                                 XGBModel(params2, num_round),\n",
    "                                 StandardScaler(), \n",
    "                                 beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[28919,     0],\n",
       "        [   70,  1394]]),\n",
       " 'accuracy': 0.9976960800447618,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.9521857923497268,\n",
       " 'f1': 0.9755073477956613,\n",
       " 'f2': 0.9613793103448276}"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_iterative_imputer.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix': array([[12367,    28],\n",
       "        [  326,   301]]),\n",
       " 'accuracy': 0.9728152357548764,\n",
       " 'precision': 0.9148936170212766,\n",
       " 'recall': 0.4800637958532695,\n",
       " 'f1': 0.6297071129707112,\n",
       " 'f2': 0.5304899541769476}"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_iterative_imputer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_no_imputer = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                                        StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                                        None,\n",
    "                                        XGBModel(params2, num_round),\n",
    "                                        StandardScaler(), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:25:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_no_imputer.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9977619063291973"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_no_imputer._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762237762237762"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_no_imputer._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9724312701581939, 0.62010582010582)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_no_imputer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Depth vs Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "forest_modeling = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                           IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                           None,\n",
    "                           StandardScaler(), beta=2)\n",
    "forest_modeling.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for i in range(4,21):\n",
    "    forest_modeling.model = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = i)\n",
    "    train_out = forest_modeling.train()\n",
    "    test_out = forest_modeling.test()\n",
    "    results = results.append({'max_depth': forest_modeling.model.max_depth,\n",
    "                    'accuracy_train': train_out['accuracy'],\n",
    "                    'f2_train': train_out['f2'],\n",
    "                    'accuracy_test': test_out['accuracy'],\n",
    "                    'f2_test': test_out['f2'] }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f2_test</th>\n",
       "      <th>f2_train</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.777079</td>\n",
       "      <td>0.398389</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.816641</td>\n",
       "      <td>0.435307</td>\n",
       "      <td>0.485645</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.839426</td>\n",
       "      <td>0.853405</td>\n",
       "      <td>0.484166</td>\n",
       "      <td>0.548102</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.882303</td>\n",
       "      <td>0.511915</td>\n",
       "      <td>0.605023</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.917322</td>\n",
       "      <td>0.526186</td>\n",
       "      <td>0.686213</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.914299</td>\n",
       "      <td>0.936149</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>0.744622</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.934956</td>\n",
       "      <td>0.958102</td>\n",
       "      <td>0.527762</td>\n",
       "      <td>0.812180</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945554</td>\n",
       "      <td>0.971431</td>\n",
       "      <td>0.512584</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.978969</td>\n",
       "      <td>0.504631</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.955537</td>\n",
       "      <td>0.984103</td>\n",
       "      <td>0.487565</td>\n",
       "      <td>0.928838</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.958685</td>\n",
       "      <td>0.988645</td>\n",
       "      <td>0.467227</td>\n",
       "      <td>0.950543</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.959991</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.447710</td>\n",
       "      <td>0.962299</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.961680</td>\n",
       "      <td>0.993615</td>\n",
       "      <td>0.421034</td>\n",
       "      <td>0.972962</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.962909</td>\n",
       "      <td>0.995491</td>\n",
       "      <td>0.416079</td>\n",
       "      <td>0.981221</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.962448</td>\n",
       "      <td>0.996511</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.985726</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.997499</td>\n",
       "      <td>0.392997</td>\n",
       "      <td>0.989724</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.964445</td>\n",
       "      <td>0.998289</td>\n",
       "      <td>0.392086</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_test  accuracy_train   f2_test  f2_train  max_depth\n",
       "0        0.767701        0.777079  0.398389  0.430108        4.0\n",
       "1        0.802795        0.816641  0.435307  0.485645        5.0\n",
       "2        0.839426        0.853405  0.484166  0.548102        6.0\n",
       "3        0.867685        0.882303  0.511915  0.605023        7.0\n",
       "4        0.899017        0.917322  0.526186  0.686213        8.0\n",
       "5        0.914299        0.936149  0.525692  0.744622        9.0\n",
       "6        0.934956        0.958102  0.527762  0.812180       10.0\n",
       "7        0.945554        0.971431  0.512584  0.865241       11.0\n",
       "8        0.952542        0.978969  0.504631  0.901639       12.0\n",
       "9        0.955537        0.984103  0.487565  0.928838       13.0\n",
       "10       0.958685        0.988645  0.467227  0.950543       14.0\n",
       "11       0.959991        0.990982  0.447710  0.962299       15.0\n",
       "12       0.961680        0.993615  0.421034  0.972962       16.0\n",
       "13       0.962909        0.995491  0.416079  0.981221       17.0\n",
       "14       0.962448        0.996511  0.398936  0.985726       18.0\n",
       "15       0.963293        0.997499  0.392997  0.989724       19.0\n",
       "16       0.964445        0.998289  0.392086  0.992537       20.0"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "results2 = pd.DataFrame()\n",
    "for i in range(4,13):\n",
    "    params = {\n",
    "    'max_depth': i,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.6\n",
    "    }\n",
    "    forest_modeling.model = XGBModel(params, num_round)\n",
    "    train_out = forest_modeling.train()\n",
    "    test_out = forest_modeling.test()\n",
    "    results2 = results2.append({'max_depth': i,\n",
    "                    'accuracy_train': train_out['accuracy'],\n",
    "                    'f2_train': train_out['f2'],\n",
    "                    'accuracy_test': test_out['accuracy'],\n",
    "                    'f2_test': test_out['f2'] }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f2_test</th>\n",
       "      <th>f2_train</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969897</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.482783</td>\n",
       "      <td>0.555807</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972508</td>\n",
       "      <td>0.978606</td>\n",
       "      <td>0.515775</td>\n",
       "      <td>0.616970</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973890</td>\n",
       "      <td>0.983609</td>\n",
       "      <td>0.570038</td>\n",
       "      <td>0.716370</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.974889</td>\n",
       "      <td>0.987296</td>\n",
       "      <td>0.576655</td>\n",
       "      <td>0.783271</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973430</td>\n",
       "      <td>0.989797</td>\n",
       "      <td>0.555362</td>\n",
       "      <td>0.827405</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973583</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.557108</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974351</td>\n",
       "      <td>0.996742</td>\n",
       "      <td>0.576589</td>\n",
       "      <td>0.945160</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973353</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>0.563282</td>\n",
       "      <td>0.971936</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.974658</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.572027</td>\n",
       "      <td>0.984641</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_test  accuracy_train   f2_test  f2_train  max_depth\n",
       "0       0.969897        0.974854  0.482783  0.555807        4.0\n",
       "1       0.972508        0.978606  0.515775  0.616970        5.0\n",
       "2       0.973890        0.983609  0.570038  0.716370        6.0\n",
       "3       0.974889        0.987296  0.576655  0.783271        7.0\n",
       "4       0.973430        0.989797  0.555362  0.827405        8.0\n",
       "5       0.973583        0.995129  0.557108  0.919220        9.0\n",
       "6       0.974351        0.996742  0.576589  0.945160       10.0\n",
       "7       0.973353        0.998321  0.563282  0.971936       11.0\n",
       "8       0.974658        0.999078  0.572027  0.984641       12.0"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "results3 = pd.DataFrame()\n",
    "for i in range(0,10):\n",
    "    eta = 0.1 + i*0.1\n",
    "    params = {\n",
    "    'max_depth': 13,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': eta\n",
    "    }\n",
    "    forest_modeling.model = XGBModel(params, num_round)\n",
    "    accuracy_train, f1_train = forest_modeling.train()\n",
    "    accuracy_test, f1_test = forest_modeling.test()\n",
    "    results3 = results3.append({'eta': eta,\n",
    "                    'accuracy_train': accuracy_train,\n",
    "                    'f1_train': f1_train,\n",
    "                    'accuracy_test': accuracy_test,\n",
    "                    'f1_test': f1_test }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>eta</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.987263</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.847818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973430</td>\n",
       "      <td>0.992529</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>0.915957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973737</td>\n",
       "      <td>0.997005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.647423</td>\n",
       "      <td>0.967924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.998618</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.640737</td>\n",
       "      <td>0.985447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.972508</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.632444</td>\n",
       "      <td>0.989648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.974044</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.995196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973430</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.651210</td>\n",
       "      <td>0.999658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973353</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.652653</td>\n",
       "      <td>0.999316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.970895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.619095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.972431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_test  accuracy_train  eta   f1_test  f1_train\n",
       "0       0.971126        0.987263  0.1  0.600000  0.847818\n",
       "1       0.973430        0.992529  0.2  0.637317  0.915957\n",
       "2       0.973737        0.997005  0.3  0.647423  0.967924\n",
       "3       0.973046        0.998618  0.4  0.640737  0.985447\n",
       "4       0.972508        0.999013  0.5  0.632444  0.989648\n",
       "5       0.974044        0.999539  0.6  0.657895  0.995196\n",
       "6       0.973430        0.999967  0.7  0.651210  0.999658\n",
       "7       0.973353        0.999934  0.8  0.652653  0.999316\n",
       "8       0.970895        1.000000  0.9  0.619095  1.000000\n",
       "9       0.972431        1.000000  1.0  0.645607  1.000000"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "XGB_Classifier_Model = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                           IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                           XGBClassifier(max_depth=13, n_estimators=30, eval_metric='mlogloss', ),\n",
    "                           StandardScaler())\n",
    "XGB_Classifier_Model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9999670868577824, 0.9996583532627262)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Classifier_Model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9755797880509907, 0.6774847870182557)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Classifier_Model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 7,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.6\n",
    "}\n",
    "\n",
    "best_xgb = ClassificationModeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                           IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                           XGBModel(params),\n",
    "                           StandardScaler(), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
