{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import warnings\\nwarnings.filterwarnings('ignore')\\nfrom warnings import simplefilter \\nsimplefilter(action='ignore', category=FutureWarning)\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import re\n",
    "import os\n",
    "from IPython.display import Image\n",
    "#import sklearn\n",
    "#import time\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# data pre-processing\n",
    "from scipy.io import arff\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.impute._base import _BaseImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection._split import BaseShuffleSplit\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# prediction models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import warnings filter\n",
    "'''import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "class FilePathManager:\n",
    "    def __init__(self, local_dir: str):\n",
    "        self.local_dir = local_dir\n",
    "    \n",
    "    def retrieve_full_path(self):\n",
    "        return os.getcwd()+'/'+self.local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARFFLoader:\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, file_path_manager: FilePathManager):\n",
    "        self.file_path_manager = file_path_manager\n",
    "    \n",
    "    def load_data(self):\n",
    "        files = self.retrieve_files()\n",
    "        for file in files:\n",
    "            self.df = pd.concat([self.df, self.load_file(file)])\n",
    "        self.df=self.df.reset_index(drop=True)\n",
    "        \n",
    "    def load_file(self, file_name):\n",
    "        return pd.DataFrame(arff.loadarff(self.file_path_manager.retrieve_full_path()+'/'+file_name)[0])\n",
    " \n",
    "    def retrieve_files(self):\n",
    "        full_path = self.file_path_manager.retrieve_full_path()\n",
    "        return [f for f in os.listdir(full_path) if os.path.isfile(join(full_path, f))]\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df;\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df: pd.DataFrame):\n",
    "    df['bankrupt'] = ( df['class'] == df['class'][df.shape[0]-1] ).astype(int)\n",
    "    df = df.drop('class', axis=1)\n",
    "    return df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_manager = FilePathManager('data')\n",
    "loader = ARFFLoader(path_manager)\n",
    "loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.51710</td>\n",
       "      <td>-14.5470</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>0.918160</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.426950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131840</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.34400</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.33820</td>\n",
       "      <td>-37.8590</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.678900</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.404370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.23810</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.22110</td>\n",
       "      <td>71.7990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318770</td>\n",
       "      <td>2.332000</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.698410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164990</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.46600</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.08280</td>\n",
       "      <td>-88.2120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285050</td>\n",
       "      <td>0.473840</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293580</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.00660</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.94440</td>\n",
       "      <td>21.7310</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.108230</td>\n",
       "      <td>1.371400</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.521670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101240</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.98740</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43400</th>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>-0.136190</td>\n",
       "      <td>0.60839</td>\n",
       "      <td>-18.4490</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.972030</td>\n",
       "      <td>1.01210</td>\n",
       "      <td>0.460840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>0.98809</td>\n",
       "      <td>0.27414</td>\n",
       "      <td>73.5050</td>\n",
       "      <td>79.23700</td>\n",
       "      <td>31.268</td>\n",
       "      <td>11.67300</td>\n",
       "      <td>5.14890</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43401</th>\n",
       "      <td>-0.013359</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>-0.022650</td>\n",
       "      <td>0.92896</td>\n",
       "      <td>-42.2320</td>\n",
       "      <td>-0.013359</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.562890</td>\n",
       "      <td>0.98904</td>\n",
       "      <td>0.328470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.040671</td>\n",
       "      <td>1.01110</td>\n",
       "      <td>0.80592</td>\n",
       "      <td>10.5990</td>\n",
       "      <td>7.17400</td>\n",
       "      <td>94.092</td>\n",
       "      <td>3.87920</td>\n",
       "      <td>1.75720</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43402</th>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.50276</td>\n",
       "      <td>0.439230</td>\n",
       "      <td>1.87360</td>\n",
       "      <td>9.7417</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.983560</td>\n",
       "      <td>1.00830</td>\n",
       "      <td>0.494490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.99174</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.4700</td>\n",
       "      <td>6.07590</td>\n",
       "      <td>51.019</td>\n",
       "      <td>7.15420</td>\n",
       "      <td>62.00100</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>-0.041643</td>\n",
       "      <td>0.84810</td>\n",
       "      <td>-0.128520</td>\n",
       "      <td>0.57485</td>\n",
       "      <td>-121.9200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036795</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>0.42138</td>\n",
       "      <td>0.151820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232720</td>\n",
       "      <td>-0.274290</td>\n",
       "      <td>0.98788</td>\n",
       "      <td>3.59310</td>\n",
       "      <td>39.7030</td>\n",
       "      <td>3.14200</td>\n",
       "      <td>261.850</td>\n",
       "      <td>1.39390</td>\n",
       "      <td>0.51005</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.94648</td>\n",
       "      <td>0.032110</td>\n",
       "      <td>1.03630</td>\n",
       "      <td>-20.5810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>2.96940</td>\n",
       "      <td>0.053341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.280210</td>\n",
       "      <td>0.97443</td>\n",
       "      <td>1.17920</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>4.17410</td>\n",
       "      <td>108.640</td>\n",
       "      <td>3.35990</td>\n",
       "      <td>35.11800</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43405 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Attr1    Attr2     Attr3    Attr4     Attr5     Attr6     Attr7  \\\n",
       "0      0.202350  0.46500  0.240380  1.51710  -14.5470  0.510690  0.253660   \n",
       "1      0.030073  0.59563  0.186680  1.33820  -37.8590 -0.000319  0.041670   \n",
       "2      0.257860  0.29949  0.665190  3.22110   71.7990  0.000000  0.318770   \n",
       "3      0.227160  0.67850  0.042784  1.08280  -88.2120  0.000000  0.285050   \n",
       "4      0.085443  0.38039  0.359230  1.94440   21.7310  0.187900  0.108230   \n",
       "...         ...      ...       ...      ...       ...       ...       ...   \n",
       "43400  0.018371  0.47410 -0.136190  0.60839  -18.4490  0.018371  0.018371   \n",
       "43401 -0.013359  0.58354 -0.022650  0.92896  -42.2320 -0.013359 -0.015036   \n",
       "43402  0.006338  0.50276  0.439230  1.87360    9.7417  0.006338  0.012022   \n",
       "43403 -0.041643  0.84810 -0.128520  0.57485 -121.9200  0.000000 -0.036795   \n",
       "43404  0.014946  0.94648  0.032110  1.03630  -20.5810  0.000000  0.015260   \n",
       "\n",
       "          Attr8    Attr9    Attr10  ...    Attr56    Attr57   Attr58   Attr59  \\\n",
       "0      0.918160  1.15190  0.426950  ...  0.131840  0.473950  0.86816  0.00024   \n",
       "1      0.678900  0.32356  0.404370  ...  0.121460  0.074369  0.87235  0.00000   \n",
       "2      2.332000  1.67620  0.698410  ...  0.164990  0.369210  0.81614  0.00000   \n",
       "3      0.473840  1.32410  0.321500  ...  0.293580  0.706570  0.78617  0.48456   \n",
       "4      1.371400  1.11260  0.521670  ...  0.101240  0.163790  0.89876  0.00000   \n",
       "...         ...      ...       ...  ...       ...       ...      ...      ...   \n",
       "43400  0.972030  1.01210  0.460840  ...  0.011909  0.039866  0.98809  0.27414   \n",
       "43401  0.562890  0.98904  0.328470  ... -0.011082 -0.040671  1.01110  0.80592   \n",
       "43402  0.983560  1.00830  0.494490  ...  0.008258  0.012817  0.99174  0.00000   \n",
       "43403  0.179010  0.42138  0.151820  ... -0.232720 -0.274290  0.98788  3.59310   \n",
       "43404  0.056357  2.96940  0.053341  ...  0.015705  0.280210  0.97443  1.17920   \n",
       "\n",
       "        Attr60    Attr61   Attr62    Attr63    Attr64  class  \n",
       "0       8.5487   5.16550  107.740   3.38790   5.34400   b'0'  \n",
       "1       1.5264   0.63305  622.660   0.58619   1.23810   b'0'  \n",
       "2       4.3325   3.19850   65.215   5.59690  47.46600   b'0'  \n",
       "3       5.2309   5.06750  142.460   2.56210   3.00660   b'0'  \n",
       "4       5.7035   4.00200   89.058   4.09840   5.98740   b'0'  \n",
       "...        ...       ...      ...       ...       ...    ...  \n",
       "43400  73.5050  79.23700   31.268  11.67300   5.14890   b'1'  \n",
       "43401  10.5990   7.17400   94.092   3.87920   1.75720   b'1'  \n",
       "43402  10.4700   6.07590   51.019   7.15420  62.00100   b'1'  \n",
       "43403  39.7030   3.14200  261.850   1.39390   0.51005   b'1'  \n",
       "43404  15.0360   4.17410  108.640   3.35990  35.11800   b'1'  \n",
       "\n",
       "[43405 rows x 65 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'    41314\n",
       "b'1'     2091\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_df()['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04817417348231771"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2091/(41314+2091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2091/(2091+0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09192016880604888"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*(1*(.04817417348231771*1.0)))/(.04817417348231771+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attr37    43.736897\n",
       "Attr21    13.486925\n",
       "Attr27     6.367930\n",
       "Attr60     4.957954\n",
       "Attr45     4.946435\n",
       "Attr24     2.124179\n",
       "Attr28     1.870752\n",
       "Attr64     1.870752\n",
       "Attr54     1.870752\n",
       "Attr53     1.870752\n",
       "Attr41     1.737127\n",
       "Attr32     0.847829\n",
       "Attr52     0.693468\n",
       "Attr47     0.684253\n",
       "Attr46     0.311024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = loader.get_df().isnull().sum()\n",
    "pct_missing = missing/loader.size()*100\n",
    "pct_missing.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseImputer:\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def transform(self, X):\n",
    "        pass\n",
    "\n",
    "class BaseModel:\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBModel:\n",
    "    _model = None\n",
    "    \n",
    "    def __init__(self, params, num_round: int):\n",
    "        self._params = params\n",
    "        self._num_round = num_round\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        dtrain = xgb.DMatrix(X, label = y)\n",
    "        self._model = xgb.train(self._params, dtrain)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self._model.predict(dtest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling:\n",
    "    _accuracy = None\n",
    "    _f1 = None\n",
    "    \n",
    "    _X_train_fitted = None\n",
    "    _X_test_fitted = None\n",
    "    _y_train = None\n",
    "    _y_test = None\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                 target_name: str, \n",
    "                 shuffle_splitter: BaseShuffleSplit, \n",
    "                 imputer: BaseImputer, \n",
    "                 model: BaseModel, scaler = None):\n",
    "        self._data = data\n",
    "        self._target_name = target_name\n",
    "        self._shuffle_splitter = shuffle_splitter\n",
    "        self._imputer = imputer\n",
    "        self._model = model\n",
    "        self._X, self._y = self._split_data()\n",
    "        self._scaler = scaler\n",
    "        \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self._model = model\n",
    "     \n",
    "    @property\n",
    "    def X_train(self):\n",
    "        return self._X_train_fitted\n",
    "    \n",
    "    @property\n",
    "    def X_test(self):\n",
    "        return self._X_test_fitted\n",
    "    \n",
    "    @property\n",
    "    def y_train(self):\n",
    "        return self._y_train\n",
    "    \n",
    "    @property\n",
    "    def y_test(self):\n",
    "        return self._y_test\n",
    "    \n",
    "    def _split_data(self):\n",
    "        X = self._data.copy()\n",
    "        return X.drop([self._target_name], axis=1) , X[self._target_name]\n",
    "    \n",
    "    def _shuffle_split(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        for train_index, test_index in self._shuffle_splitter.split(X,y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def _fit_imputer(self, train):\n",
    "        self._imputer.fit(train)\n",
    "    \n",
    "    def _fit_scaler(self, train):\n",
    "        if self._scaler is not None:\n",
    "            self._scaler.fit(train)\n",
    "    \n",
    "    def _impute_data(self, X: pd.DataFrame):\n",
    "        return pd.DataFrame(self._imputer.transform(X), columns = self.X.columns, index = X.index)\n",
    "    \n",
    "    def _scale_data(self, X: pd.DataFrame):\n",
    "        if self._scaler is not None:\n",
    "            X = pd.DataFrame(self._scaler.transform(X), columns = self._X.columns)\n",
    "        return X\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        X_train, X_test, y_train, y_test = self._shuffle_split()   \n",
    "        self._fit_imputer(X_train)\n",
    "        X_train = self._impute_data(X_train)\n",
    "        X_test = self._impute_data(X_test)\n",
    "        self._fit_scaler(X_train)\n",
    "        self._X_train_fitted = self._scale_data(X_train)\n",
    "        self._X_test_fitted = self._scale_data(X_test)\n",
    "        self._y_train = y_train\n",
    "        self._y_test = y_test\n",
    "        \n",
    "    def prepare_and_train(self):\n",
    "        self.prepare_data()\n",
    "        self.train()\n",
    "        \n",
    "    def train(self):\n",
    "        self._model.fit(self.X_train, self.y_train)\n",
    "        preds =  self._model.predict(self.X_train)\n",
    "        self._accuracy = accuracy_score(self.y_train, preds)\n",
    "        self._f1 = f1_score(self.y_train, preds)\n",
    "        return self._accuracy, self._f1\n",
    "        \n",
    "    def test(self):\n",
    "        preds = self._model.predict(self.X_test)\n",
    "        return (accuracy_score(self.y_test, preds), f1_score(self.y_test, preds))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_impute_model = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                               StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                               SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "                               RandomForestClassifier(random_state=0, class_weight='balanced', max_depth=12),\n",
    "                               StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_impute_model.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759075798966528"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_impute_model._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7934537246049662"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_impute_model._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9462448164644448, 0.44794952681388017)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_impute_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_impute_model = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                               StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                               IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                               RandomForestClassifier(random_state=0, class_weight='balanced', max_depth=14),\n",
    "                               StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "iterative_impute_model.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789685021228977"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_impute_model._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8162208800690249"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_impute_model._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9525418522500384, 0.5056)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_impute_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_impute_model = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                            StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=1234),\n",
    "                            KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean'),\n",
    "                            RandomForestClassifier(random_state=0, class_weight='balanced'),\n",
    "                            StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_impute_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_impute_model._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_impute_model._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9524650591307019, 0.09635036496350363)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_impute_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 1000\n",
    "params = {\n",
    "    'max_depth': 12,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_simple_imputer = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                 StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                 SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "                 XGBModel(params, num_round),\n",
    "                 StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:59:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_simple_imputer.prepare_and_train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821610769180134"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_simple_imputer._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7732217573221758"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_simple_imputer._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.968975579788051, 0.5826446280991736)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_simple_imputer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    'max_depth': 15,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_iterative_imputer = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                 StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                 IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                 XGBModel(params2, num_round),\n",
    "                 StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_iterative_imputer.prepare_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976960800447618"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_iterative_imputer._accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755073477956613"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_iterative_imputer._f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9728152357548764, 0.6297071129707112)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_iterative_imputer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Depth vs Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "forest_modeling = Modeling(clean_df(loader.get_df()),'bankrupt',\n",
    "                           StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=12343),\n",
    "                           IterativeImputer(missing_values=np.nan, random_state=1234),\n",
    "                           None,\n",
    "                           StandardScaler())\n",
    "forest_modeling.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for i in range(4,21):\n",
    "    forest_modeling.model = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = i)\n",
    "    accuracy_train, f1_train = forest_modeling.train()\n",
    "    accuracy_test, f1_test = forest_modeling.test()\n",
    "    results = results.append({'max_depth': forest_modeling.model.max_depth,\n",
    "                    'accuracy_train': accuracy_train,\n",
    "                    'f1_train': f1_train,\n",
    "                    'accuracy_test': accuracy_test,\n",
    "                    'f1_test': f1_test }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.777079</td>\n",
       "      <td>0.235145</td>\n",
       "      <td>0.255141</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.816641</td>\n",
       "      <td>0.267541</td>\n",
       "      <td>0.301267</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.839426</td>\n",
       "      <td>0.853405</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.358028</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.882303</td>\n",
       "      <td>0.350057</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.917322</td>\n",
       "      <td>0.393170</td>\n",
       "      <td>0.509758</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.914299</td>\n",
       "      <td>0.936149</td>\n",
       "      <td>0.416928</td>\n",
       "      <td>0.580631</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.934956</td>\n",
       "      <td>0.958102</td>\n",
       "      <td>0.462904</td>\n",
       "      <td>0.681670</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945554</td>\n",
       "      <td>0.971431</td>\n",
       "      <td>0.485113</td>\n",
       "      <td>0.762322</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.978969</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.816221</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.955537</td>\n",
       "      <td>0.984103</td>\n",
       "      <td>0.507234</td>\n",
       "      <td>0.856464</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.958685</td>\n",
       "      <td>0.988645</td>\n",
       "      <td>0.508227</td>\n",
       "      <td>0.893879</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.959991</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.501435</td>\n",
       "      <td>0.914214</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.961680</td>\n",
       "      <td>0.993615</td>\n",
       "      <td>0.491335</td>\n",
       "      <td>0.937741</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.962909</td>\n",
       "      <td>0.995491</td>\n",
       "      <td>0.494241</td>\n",
       "      <td>0.955273</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.962448</td>\n",
       "      <td>0.996511</td>\n",
       "      <td>0.479233</td>\n",
       "      <td>0.965063</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.997499</td>\n",
       "      <td>0.479303</td>\n",
       "      <td>0.974700</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.964445</td>\n",
       "      <td>0.998289</td>\n",
       "      <td>0.484983</td>\n",
       "      <td>0.982539</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_test  accuracy_train   f1_test  f1_train  max_depth\n",
       "0        0.767701        0.777079  0.235145  0.255141        4.0\n",
       "1        0.802795        0.816641  0.267541  0.301267        5.0\n",
       "2        0.839426        0.853405  0.313300  0.358028        6.0\n",
       "3        0.867685        0.882303  0.350057  0.415686        7.0\n",
       "4        0.899017        0.917322  0.393170  0.509758        8.0\n",
       "5        0.914299        0.936149  0.416928  0.580631        9.0\n",
       "6        0.934956        0.958102  0.462904  0.681670       10.0\n",
       "7        0.945554        0.971431  0.485113  0.762322       11.0\n",
       "8        0.952542        0.978969  0.505600  0.816221       12.0\n",
       "9        0.955537        0.984103  0.507234  0.856464       13.0\n",
       "10       0.958685        0.988645  0.508227  0.893879       14.0\n",
       "11       0.959991        0.990982  0.501435  0.914214       15.0\n",
       "12       0.961680        0.993615  0.491335  0.937741       16.0\n",
       "13       0.962909        0.995491  0.494241  0.955273       17.0\n",
       "14       0.962448        0.996511  0.479233  0.965063       18.0\n",
       "15       0.963293        0.997499  0.479303  0.974700       19.0\n",
       "16       0.964445        0.998289  0.484983  0.982539       20.0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "results2 = pd.DataFrame()\n",
    "for i in range(4,21):\n",
    "    params = {\n",
    "    'max_depth': i,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': 0.3\n",
    "    }\n",
    "    forest_modeling.model = XGBModel(params, num_round)\n",
    "    accuracy_train, f1_train = forest_modeling.train()\n",
    "    accuracy_test, f1_test = forest_modeling.test()\n",
    "    results2 = results2.append({'max_depth': i,\n",
    "                    'accuracy_train': accuracy_train,\n",
    "                    'f1_train': f1_train,\n",
    "                    'accuracy_test': accuracy_test,\n",
    "                    'f1_test': f1_test }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967824</td>\n",
       "      <td>0.969917</td>\n",
       "      <td>0.506478</td>\n",
       "      <td>0.549310</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.970358</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.563348</td>\n",
       "      <td>0.618062</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971049</td>\n",
       "      <td>0.975611</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.662107</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.971971</td>\n",
       "      <td>0.979462</td>\n",
       "      <td>0.603692</td>\n",
       "      <td>0.729402</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.794069</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973583</td>\n",
       "      <td>0.986769</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>0.840855</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973814</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>0.642932</td>\n",
       "      <td>0.884996</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973890</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>0.643606</td>\n",
       "      <td>0.921547</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.972815</td>\n",
       "      <td>0.995425</td>\n",
       "      <td>0.627368</td>\n",
       "      <td>0.950161</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.973737</td>\n",
       "      <td>0.997005</td>\n",
       "      <td>0.647423</td>\n",
       "      <td>0.967924</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.973199</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>0.639090</td>\n",
       "      <td>0.972271</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.972815</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.629707</td>\n",
       "      <td>0.975507</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.972431</td>\n",
       "      <td>0.998157</td>\n",
       "      <td>0.624084</td>\n",
       "      <td>0.980501</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.972969</td>\n",
       "      <td>0.998618</td>\n",
       "      <td>0.640816</td>\n",
       "      <td>0.985447</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.972508</td>\n",
       "      <td>0.998651</td>\n",
       "      <td>0.628631</td>\n",
       "      <td>0.985798</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.972431</td>\n",
       "      <td>0.998585</td>\n",
       "      <td>0.631038</td>\n",
       "      <td>0.985095</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973199</td>\n",
       "      <td>0.998848</td>\n",
       "      <td>0.641316</td>\n",
       "      <td>0.987902</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_test  accuracy_train   f1_test  f1_train  max_depth\n",
       "0        0.967824        0.969917  0.506478  0.549310        4.0\n",
       "1        0.970358        0.973275  0.563348  0.618062        5.0\n",
       "2        0.971049        0.975611  0.580645  0.662107        6.0\n",
       "3        0.971971        0.979462  0.603692  0.729402        7.0\n",
       "4        0.973046        0.983543  0.623794  0.794069        8.0\n",
       "5        0.973583        0.986769  0.632479  0.840855        9.0\n",
       "6        0.973814        0.990060  0.642932  0.884996       10.0\n",
       "7        0.973890        0.992990  0.643606  0.921547       11.0\n",
       "8        0.972815        0.995425  0.627368  0.950161       12.0\n",
       "9        0.973737        0.997005  0.647423  0.967924       13.0\n",
       "10       0.973199        0.997400  0.639090  0.972271       14.0\n",
       "11       0.972815        0.997696  0.629707  0.975507       15.0\n",
       "12       0.972431        0.998157  0.624084  0.980501       16.0\n",
       "13       0.972969        0.998618  0.640816  0.985447       17.0\n",
       "14       0.972508        0.998651  0.628631  0.985798       18.0\n",
       "15       0.972431        0.998585  0.631038  0.985095       19.0\n",
       "16       0.973199        0.998848  0.641316  0.987902       20.0"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "results3 = pd.DataFrame()\n",
    "for i in range(0,10):\n",
    "    eta = 0.1 + i*0.1\n",
    "    params = {\n",
    "    'max_depth': 13,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'eta': eta\n",
    "    }\n",
    "    forest_modeling.model = XGBModel(params, num_round)\n",
    "    accuracy_train, f1_train = forest_modeling.train()\n",
    "    accuracy_test, f1_test = forest_modeling.test()\n",
    "    results3 = results3.append({'eta': eta,\n",
    "                    'accuracy_train': accuracy_train,\n",
    "                    'f1_train': f1_train,\n",
    "                    'accuracy_test': accuracy_test,\n",
    "                    'f1_test': f1_test }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>eta</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.987263</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.847818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973430</td>\n",
       "      <td>0.992529</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>0.915957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973737</td>\n",
       "      <td>0.997005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.647423</td>\n",
       "      <td>0.967924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.998618</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.640737</td>\n",
       "      <td>0.985447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.972508</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.632444</td>\n",
       "      <td>0.989648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.974044</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.995196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973430</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.651210</td>\n",
       "      <td>0.999658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973353</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.652653</td>\n",
       "      <td>0.999316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.970895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.619095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.972431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_test  accuracy_train  eta   f1_test  f1_train\n",
       "0       0.971126        0.987263  0.1  0.600000  0.847818\n",
       "1       0.973430        0.992529  0.2  0.637317  0.915957\n",
       "2       0.973737        0.997005  0.3  0.647423  0.967924\n",
       "3       0.973046        0.998618  0.4  0.640737  0.985447\n",
       "4       0.972508        0.999013  0.5  0.632444  0.989648\n",
       "5       0.974044        0.999539  0.6  0.657895  0.995196\n",
       "6       0.973430        0.999967  0.7  0.651210  0.999658\n",
       "7       0.973353        0.999934  0.8  0.652653  0.999316\n",
       "8       0.970895        1.000000  0.9  0.619095  1.000000\n",
       "9       0.972431        1.000000  1.0  0.645607  1.000000"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
